{
  
    
        "post0": {
            "title": "Learning The Docker",
            "content": "What is Docker . Docker is a software platform that allows developer to build, test and deploy application quickly. In the nut shell, docker can deploy the developer application into different running environment. Let&#39;s say, someone with a &quot;Node&quot; with a different version can still run the application as the same as the developer have. . Docker compose of three main parts: . Docker files (Blue print of the Image. We need to modify this file to export our application) | Image (Environment, eg. Ubuntu, Node version, etc.) | Container (The package.json file, which contain all the library and the depandency.) | . Why use Docker . Docker enable the developer to develop at the local environment and ship easily. . How . First, download the Docker destop app here, which have both Mac and Window Version. Docker destop app contain a GUI, which can be more user-friendly for begineers. . Second, if using Visual Studio code, you can also install the docker extension, and run it internally with VS code terminal. . Common commands for Docker . terminal docker ps docker build docker run docker pull docker tag docker push . Writing an docker file . FROM used to specify Docker Image Name and start the build process . #specify a Base Image FROM ubuntu:latest FROM node:12 . Maintainer used to about the person who creates the Docker Image . MAINTAINER support@fosstechnix.com . CMD used to execute a command in Running container, There should be one CMD in a Dockerfile. . # To run apache2 in foreground CMD [&quot;/usr/sbin/apache2&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;] . RUN used to execute any commands on top of current Docker Image. . RUN executes the command when you are building Image. . FROM ubuntu:latest MAINTAINER support@fosstechnix.com RUN apt-get update RUN apt-get install -y apache2 . EXPOSE used to specify Network port for Docker container . # To Expose port 80 of Docker container EXPOSE 80 EXPOSE 8080/tcp . ENV used to set Environment Variables with key and value. . FROM node:12 ENV workdirectory /usr/node . VOLUME used to create or mount volume to docker container. . FROM node:12 RUN mkdir /node WORKDIR /node RUN echo &quot;Welcome to Node.js&quot; &gt; node VOLUME /node . Reference . Docker | AWS | Docker Cheat Sheet | Docker file Instructions | .",
            "url": "https://aungpaing98.github.io/blogs/software/docker/notes/2021/07/08/Docker.html",
            "relUrl": "/software/docker/notes/2021/07/08/Docker.html",
            "date": " • Jul 8, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Study Web from Scratch Notes",
            "content": "Why I started to learn Front-end . It seems like the end of study the machine learning is representing the model, and to the customer, to yourself. I am not saying I am already an expert in Machine Learning, not at all yet. But visualization of deep learning model intrigue me, how is the intermediate(hidden) layer of the model is behaving? Then I have a idea of putting my visualization model online. For that, I will have to know front-end. So my jorney to become front-end start. . How I start my Jornel . The very first thing is advice. I looked for all kinds of advices. Then plan for the whole course, what to study, and what I will focus on. Then, I decided to put main learning time on this website, as this have complete blog posts about every details I need to know as begineer. . So, Let&#39;s get start . Day1 . 2020-1-12-Tuesday . URL . URL stand for Uniform Resoure Locator, Each and every website on the cloud have its own URL, it is like an id. When we make a REQUEST throught the web, it is searching for that URL in the cloud and return us the website from that URL. But, actually, it is not URL that is the actual id of the website, IP is. . IP . IP stands for Internet Protocal, It is the id of the website. . For example, This block . URL IP . https://aungpaing98.github.io/blogs/ | 185.199.108.153 | . HTML . HTML stands for Hyper-Text Markup Language. HTML, with CSS are not programming language, they have no logics, conditions, loops and so on. They focus on the properties, style and layout(position) of the specific text in whole page. . As mentioned in the video, I will need to learn much more about HTML. . Document Sectioning | Document Meta-Data | Block Text Semantics | Inline Text Semantics | Image &amp; Multimedia | Embedded Contents | Scripting | Data Tables | . CSS . CSS stands for Cascading Style Sheet. We can use CSS to basically style each and every elements from HTML. Because there are repeatly used of same tag in a HTML file, using CSS can help to style all the tag which have similar semantic or properties with just one line. . JavaScript . JavaScript was first invented in 1995. Aside from the history, javascript is the real programming that provide the user interactivity and data storage for the webpage. . There are two main javascript that I was introduced. . Server Side (Backend?) | Browser Side (Frontend?) | . Seems like the server side and brower side have huge difference. For now, I guess for the browser side, the browser will have the function of Request for the data, Parsing the documents from the request, Layout and Painting the content. Furthermore, the browser will have to secure the user information from attack. And doing all this with minimum energy and delayed. . For the server side, the server will have to Provide the documents upon request, Store user information if passed. And Backup the information, making sure no data is loss due to breakdown on electricity. . Well, that is all my guess for now. I will get to that later. . SVG . SVG stands for Scalable Vector Grphic. What we saw images in typical format are .jpg or .png format. These are in bitmaps format. where the image is composed of bits, where SVG is composed of equations describing the line in that graphic(image). . The main advantage of SVG over jpg and png is that, it is scalable to any size and will not lose information, cause it is just the equation on the backbone. . For that, I will have to study grapic Software, like Sketch or Adobe Illustrator, which I have no idea about yet. . Day2 . 2020-1-13-Wednesday . Basic CSS . Like HTML, CSS is just a markup language. It is mainly used to style the HTML elements. . Selector . Selector in the CSS indicate the tag that we want to style on. Since there are many types of tags in HTML, there are also many types of Selector in CSS. . Selector css html element . Element Selector/ Tag Selector/ Type Selector | p {} | &lt;p&gt;&lt;/p&gt; | . ID Selector | #my-id {} | &lt;p id=&#39;my-id&#39;&gt;&lt;/p&gt; | . Class Selector | my-class {} | &lt;p class=&#39;myclass&#39;&gt;&lt;/p&gt; | . Attribute Selector | img[src] {} | &lt;img src=&quot;.jpg&quot;&gt; | . Pseudo-Class Selector | a.hover | work when mouse hover the link. | . Difference Types of Elements . Block Element . eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values. . Inline Element . eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block. . Basic Java Script . Java Script is the programming language. So, first let&#39;s start with definding a variable. . Variables . let a = &quot;Hello&quot; var b = &quot;World&quot; . Conditionals . if (condition) { DO THIS }else{ DO THIS } . Function . function name(*args, **kwargs) { } . Default Built-in Methods . alert : warning up when opening the webpage. | prompt : prompt window when opening the webpage. | getAttribute(&#39;color&#39;) : get color attribute of tag | setAttribute(&#39;color&#39;) : set color attribute of tag | document.querySelector(&#39;h1&#39;) : select h1 element | localStorage.setItem() : use localStoage API to store data | localStorage.getItem() : get data from localStoage API. | . Day3 . 2020-1-14-Thursday . What is in the head? . Head of the HTML part play the whole page information, including Title, description, charset, name, author, contents, linking to css and javascript. . Important: A nice website come from a nice head section. For example, the title and description in the web can affect the search result. The charset and lang in html affect the accessability of the website, for those who have difficultly in hearing. . eg. OpenGraphData from Facebook : . &lt;meta properties=&#39;og.image&#39; content=&quot;my profile.png&quot;&gt; . which will share the profile image as the thumbnail through social media for the post. . // defer here mean run HTML first, then run javascript &lt;script src=&quot;&quot; defer&gt;&lt;/script&gt; . // Increase Accessability &lt;html lang=&#39;en-US&#39;&gt; . HTML Text Fundamentals . tags in HTML use &lt;&gt; which give the text structure and meaning, it is also called Semantics. Using the right semantic can very mush improve your webpage quaility, both in search and accessability. . When writing texts in a web, or blog post, first, to be aware is making the hierarchy right. Title (&lt;h1&gt;) then subtilte (h2) and so on. . Also, with use of emphasize in html, it is better to be careful. . &lt;strong&gt; Use to Really Emphasize words. | &lt;em&gt; use to emphasize words. | &lt;b&gt; Make words bold. Not recommanded. | &lt;i&gt; Make words Italic. Not recommanded. | . Advanced Text Formatting . Advanced text formatting including learning more tag semantics. . description list : &lt;dl&gt; | description term : &lt;dl&gt; | description defination : &lt;dd&gt; | block quotes : &lt;blockquote cite=&quot;&quot;&gt; &lt;/blockquote&gt; | inline quotes : &lt;q&gt; &lt;/q&gt; | citation : &lt;cite&gt; &lt;/cite&gt; | Abbreviations : &lt;abbr&gt; | address : &lt;address&gt; &lt;/address&gt; | super and sub script : &lt;sup&gt; &lt;sub&gt; | computer code : &lt;code&gt; &lt;/code&gt; | indentation : &lt;pre&gt; &lt;/pre&gt; (container for code block where indendation is important : python.) | variable name : &lt;var&gt; | keyboard : &lt;kbd&gt; | output : &lt;samp&gt; | timestamp : &lt;time datetime=&quot;2021-1-11&quot;&gt; | . Creating Hyperlink . Simple linking: . &lt;a href = &quot;my.com&quot;&gt;Link to website&lt;/a&gt; &lt;a href = &quot;index.html&quot;&gt;Link to HTML File&lt;/a&gt; &lt;a href = &quot;#id&quot;&gt;Link to ID element&lt;/a&gt; &lt;a href = &quot;mailto:aungpaingcha1@gmail.com&quot;&gt;Mail to Aung Paing&lt;/a&gt; . Day4 . 2020-1-15-Friday . Document and Website Structure . Basic Structures of the webpage include: . header &lt;header&gt; | navigation bar &lt;nav&gt; | main content &lt;main&gt; | sidebar &lt;aside&gt; | footer &lt;footer&gt; | . . Planning a compelet websites . Steps you must go throught for minimum effort for maximum efficiency. . Common Specifications / Nav bar / Footer, etc. | Draw Sketch / Decide contents will be in the page. | brainstorm all other pages. | Card Sorting / Sort all contents into groups. | Sketch the whole rough site map. | Into Coding. | Debugging in HTML . The first thing we should know before going on, is that HTML is not a programming language. And in the browser side, it is not compile, but interpreted. And HTML is permissive code, meaning it will run even if there are some error. The language itself is designed to be that way, because back in the day, if it is not, most developer might find it difficult to work with. And HTML will not be here today. . Like most language, the error in HTML mainly consists of: . Syntax Error | Logic Error | . We can validate our .html file in https://validator.w3.org website. . Technical Terms . HTML (Hyper-Text Markup Language) CSS (Cascading Style Sheet) SVG (Scalable Vector Graphic) URL (Uniform Resource Locator) DOM (Document Object Model) Block Element : eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values, &lt;div&gt; is also and block element. Inline Element : eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block, &lt;span&gt; is also and inline element. .",
            "url": "https://aungpaing98.github.io/blogs/front-end/notes/html/css/javascript/2021/07/07/Web-Study-Notes.html",
            "relUrl": "/front-end/notes/html/css/javascript/2021/07/07/Web-Study-Notes.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "CS231N Study Note",
            "content": "Abstrast . This course conducted by Standford focus on Computer Vision and Deep Learning, and is focus from the basic to the somehow advanced topic. This notebook contain the archives of the note of me taking from the course. If you would like to contribute to the notebook, please leave a comment in the below of the notebook. Link to youtube lecture . Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition . Brief introduction to the history of Computer Vision, Deep Learning and the problems to tackle in Computer Vision. Link to my Note . Lecture 2 | Image Classification Pipelines . Introduction to the image classification pipelines and train a simple model for image classification. Link to my Note . Lecture 3 | Loss Function and Optimization . Introduction to hinge loss, softmax function and optimization. Link to my Note . Lecture 4 | Backpropagation and Neural Network . Introduction to Neural Network backpropagation flow, equations and intuiation. Link to my Note . Lecture 5 | Convolutional Neural Network . History and modern about CNN and its basic operations. Link to my Note . Lecture 6 | Training Neural Network 1 . Basic Training Procedure hyperparameters optimization. Link to my Note . Lecture 7 | Training Neural Network 2 . Basic Training Procedure hyperparameters optimization. Link to my Note .",
            "url": "https://aungpaing98.github.io/blogs/cs231n/computer-vision/deep-learning/notes/2021/07/07/Standford-CS231N-Notes.html",
            "relUrl": "/cs231n/computer-vision/deep-learning/notes/2021/07/07/Standford-CS231N-Notes.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Learning The Docker",
            "content": "What is Docker . Docker is a software platform that allows developer to build, test and deploy application quickly. In the nut shell, docker can deploy the developer application into different running environment. Let&#39;s say, someone with a &quot;Node&quot; with a different version can still run the application as the same as the developer have. . Docker compose of three main parts: . Docker files (Blue print of the Image. We need to modify this file to export our application) | Image (Environment, eg. Ubuntu, Node version, etc.) | Container (The package.json file, which contain all the library and the depandency.) | . Why use Docker . Docker enable the developer to develop at the local environment and ship easily. . How . First, download the Docker destop app here, which have both Mac and Window Version. Docker destop app contain a GUI, which can be more user-friendly for begineers. . Second, if using Visual Studio code, you can also install the docker extension, and run it internally with VS code terminal. . Common commands for Docker . terminal docker ps docker build docker run docker pull docker tag docker push . Writing an docker file . FROM used to specify Docker Image Name and start the build process . #specify a Base Image FROM ubuntu:latest FROM node:12 . Maintainer used to about the person who creates the Docker Image . MAINTAINER support@fosstechnix.com . CMD used to execute a command in Running container, There should be one CMD in a Dockerfile. . # To run apache2 in foreground CMD [&quot;/usr/sbin/apache2&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;] . RUN used to execute any commands on top of current Docker Image. . RUN executes the command when you are building Image. . FROM ubuntu:latest MAINTAINER support@fosstechnix.com RUN apt-get update RUN apt-get install -y apache2 . EXPOSE used to specify Network port for Docker container . # To Expose port 80 of Docker container EXPOSE 80 EXPOSE 8080/tcp . ENV used to set Environment Variables with key and value. . FROM node:12 ENV workdirectory /usr/node . VOLUME used to create or mount volume to docker container. . FROM node:12 RUN mkdir /node WORKDIR /node RUN echo &quot;Welcome to Node.js&quot; &gt; node VOLUME /node . Reference . Docker | AWS | Docker Cheat Sheet | Docker file Instructions | .",
            "url": "https://aungpaing98.github.io/blogs/software/docker/notes/2021/07/07/Docker.html",
            "relUrl": "/software/docker/notes/2021/07/07/Docker.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "CS50 Study Note",
            "content": "Notes . This notebook is referenced from the CS50 course conducted by MIT lectures online from youtube. The course can be found in this youtube link. . Previews . My programming jorney starts from 3 years ago, when I first learn Python from youtube. It is a easy programming compare to others. Before that, I have attended lectures from university for basic comptuer science in C++ language. It was not a very productive one. And after I learnt Python, it is superficial, I now know that, to get the best performance of the algorithms, I need to know the logic behind all the pre-built function. That is why I started learning this course. . CS50, this lecture is really one of the top in my favorate list from my learning jorney. The lectures is energetic, explaning the lowest detail of the programming. I wish I have seen this lecture sooner. . Lectures 1 - C . The lecture is mainly conducted with using C langauge in first 5 lectures of the course. C language is the low level language meaning we can get the best performance in speed compare to other languages if the algorithms is optimized. . Good coding practice . To get the most efficient code, meaning it is functionable, able to get the desired output, it have a good design, most efficient and it have a good style, so everyone can understand the code. . $$ Code begin{cases} quad text{Functionable} quad text{Design} quad text{Style} end{cases} $$Command Line Interface (CLI) and Graphic User Interface (GUI) . Developer often use command line (terminal in mac) to execute the program. CLI is less user friendly than GUI, it needs a bit more knowledge but it is hackable and origin. The terminal is a platform which we can use complier to compile the code to machine code and open that machine code to get the output of the program. . So, the typical process is, . Write the code with text editor (visual studio code, atom, etc) | Compile the code in terminal with compiler and output machine code. | Run the machine code and output the result in terminal. | . Compiler is the program that is pre-written to convert the code that we write to machine code, that the computer understand. Different language have different compiler. And in mac, we need to install X-Code to run C program cause X-code is the compiler that contain multiple languages including C. .",
            "url": "https://aungpaing98.github.io/blogs/computer_science/basic/algorithms/2021/07/07/CS50.html",
            "relUrl": "/computer_science/basic/algorithms/2021/07/07/CS50.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Notes from Advanced Numpy (Scipy Japan 2019)",
            "content": "Abstrast . &quot;Scipy Japan 2019&quot;is the 18th annual Scientific Computing with Python conference. This note is taken from the &quot;Advanced Numpy&quot; topic, speech by Juan Nunez-Iglesias. The source code for speech is available at github. . I came across this on youtube. The speech give some aspect of Numpy that I am getting confused before, so, this notebook helps me to get more hand on Numpy. Let&#39;s get started. . A Little Introduction to DNA and RNA . The author is originally from the biologist background, so he introduced some ideas about DNA and RNA. Althought it is not much relevent to the subject, it is nice to know new things. . . Difference between List and Numpy Array . When we defind a variable in list, the true value of each element in the list is the pointer, which point to the location in hardware about where the value is stored. And each element is stored in different place. Making the list take more space and require more time to get accessed. . While in Numpy, the arrays are stored in continuous funciton. So, one array will need only one pointer value to get accessed to all elements in that array. . import numpy as np array_obj = np.arange(12, dtype=np.uint8).reshape((3, 4)) def print_info(a): print(&#39;number of elements:&#39;, a.size) print(&#39;number of dimensions:&#39;, a.ndim) print(&#39;shape:&#39;, a.shape) print(&#39;data type:&#39;, a.dtype) print(&#39;strides:&#39;, a.strides) print(&#39;flags:&#39;) print(a.flags) print_info(array_obj) . . number of elements: 12 number of dimensions: 2 shape: (3, 4) data type: uint8 strides: (4, 1) flags: C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . In about example, each element is of dtype: uint8, so it take 1 bytes. To reach the first element in next row, it would have to skip 4 bytes. so the stride is (4, 1). . &quot;C_CONTIGUOUS&quot; and &quot;F_CONTIGUOUS&quot; states whether the variable is taking value from memory from column contiguous or fortran contiguous. For more explaination, I suggest this answer on stack-overflow. . print(&quot;Transpose array : Strides Changed.&quot;) # Taking Transpose print(array_obj.T) print_info(array_obj.T) print(array_obj.T.ravel(order=&quot;F&quot;)) print_info(array_obj.T.ravel(order=&quot;F&quot;)) print(array_obj.T.ravel(order=&quot;C&quot;)) print_info(array_obj.T.ravel(order=&quot;C&quot;)) . . Transpose array : Strides Changed. [[ 0 4 8] [ 1 5 9] [ 2 6 10] [ 3 7 11]] number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 4) flags: C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 1 2 3 4 5 6 7 8 9 10 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 4 8 1 5 9 2 6 10 3 7 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . Transposing the array change the behaviour of C_CONTIGUOUS and F_CONTIGUOUS. . Broadcasting . a = np.arange(12, dtype=np.uint8).reshape((4, 3)) b = np.arange(3, dtype=np.uint8) c= np.arange(4, dtype=np.uint8) print(a.shape, b.shape, c.shape) print(a + b) print(a + c) . . (4, 3) (3,) (4,) [[ 0 2 4] [ 3 5 7] [ 6 8 10] [ 9 11 13]] . ValueError Traceback (most recent call last) &lt;ipython-input-9-059306ffba40&gt; in &lt;module&gt; 7 8 print(a + b) -&gt; 9 print(a + c) ValueError: operands could not be broadcast together with shapes (4,3) (4,) . Boradcasting in numpy works when the less dimension is right align with more dimension array. . So, (4, 3) with (3, ) will work, but not with (4, ). (3, ) -&gt; ([4], 3) (4, ) -&gt; ([4], 4) . np.broadcast_arrays, broadcast the array to the desired shape. Notice the strides of dc, is (1, 0), because the row axis&#39; element is broadcasted. . da, dc = np.broadcast_arrays(a, c[:, np.newaxis]) print_info(dc) . . number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 0) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True (with WARN_ON_WRITE=True) ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . While nb.broadcast_arrys() take one array as reference and broadcast the other array to the same shape as reference one, we can also manipulate the arr to any shape we want withnp.lib.stride_tricks.as_strided(). . def repeat(arr, size): return np.lib.stride_tricks.as_strided( arr, shape=(size, ) + (arr.shape), strides = (0, ) + (arr.strides)) print(repeat(b, 5)) print_info(repeat(b, 5)) . . [[0 1 2] [0 1 2] [0 1 2] [0 1 2] [0 1 2]] number of elements: 15 number of dimensions: 2 shape: (5, 3) data type: uint8 strides: (0, 1) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . This function is often used to find the sliding window of the given array. . def sliding_window(arr, win_size): sliding_win = np.lib.stride_tricks.as_strided( arr, shape = (arr.shape[0]-win_size+1, win_size), strides = (arr.strides[0], arr.strides[0])) return sliding_win a = np.arange(10, dtype=np.uint8) print(sliding_window(a, 3)) print(np.mean(sliding_window(a, 3), axis=1)) . . [[0 1 2] [1 2 3] [2 3 4] [3 4 5] [4 5 6] [5 6 7] [6 7 8] [7 8 9]] [1. 2. 3. 4. 5. 6. 7. 8.] . Let&#39;s do something more exciting. We will find the mean of the sliding window. Resulting in the smoother graph. And we will then find mock moving average. . import matplotlib.pyplot as plt import numpy as np import altair as alt import pandas as pd indexs = np.arange(100) random_arrays = np.random.normal(0, 0.5, size=100) # Add some curve to the graph : Sexy, hehe random_arrays[30:60] += 1 # Let&#39;s smooth it out mean_2 = np.mean(sliding_window(random_arrays, 2), axis=1) padded_mean_2 = np.pad(mean_2, (1, 0)) mean_5 = np.mean(sliding_window(random_arrays, 5), axis=1) padded_mean_5 = np.pad(mean_5, (1, 3)) simple_ema = np.array([0.1, 0.15, 0.2, 0.25, 0.3]) ema_size = simple_ema.size ema = sliding_window(np.pad(random_arrays, (ema_size, ema_size-1), &#39;reflect&#39;), ema_size) * simple_ema ema = np.sum(ema, axis=1)[:-5] df = pd.DataFrame({ &#39;index&#39;:np.hstack((indexs, indexs, indexs, indexs)), &#39;values&#39;:np.hstack([random_arrays, padded_mean_2, padded_mean_5, ema]), &#39;label&#39;:[j for j in [&#39;random_arrays&#39;, &#39;mean with 2 neighbour&#39;, &#39;mean with 5 neighbour&#39;, &#39;mock Exponential Moving Average&#39;] for _ in range(100)] }) # Create a selection that chooses the nearest point &amp; selects based on x-value nearest = alt.selection(type=&#39;single&#39;, nearest=True, on=&#39;mouseover&#39;, fields=[&#39;index&#39;], empty=&#39;none&#39;) # The basic line line = alt.Chart(df).mark_line(interpolate=&#39;basis&#39;).encode( x=&#39;index:Q&#39;, y=&#39;values:Q&#39;, color=&#39;label:N&#39; ) # Transparent selectors across the chart. This is what tells us # the x-value of the cursor selectors = alt.Chart(df).mark_point().encode( x=&#39;index:Q&#39;, opacity=alt.value(0), ).add_selection( nearest ) # Draw points on the line, and highlight based on selection points = line.mark_point().encode( opacity=alt.condition(nearest, alt.value(1), alt.value(0)) ) # Draw text labels near the points, and highlight based on selection text = line.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=alt.condition(nearest, &#39;values:Q&#39;, alt.value(&#39; &#39;)) ) # Draw a rule at the location of the selection rules = alt.Chart(df).mark_rule(color=&#39;gray&#39;).encode( x=&#39;index:Q&#39;, ).transform_filter( nearest ) # Put the five layers into a chart and bind the data alt.layer( line, selectors, points, rules, text ).properties( width=600, height=300 ) # plt.plot(random_arrays, label=&#39;origin&#39;) # plt.plot(mean_2, label=&#39;mean with 2 neighbour&#39;) # plt.plot(mean_5, label=&#39;mean with 5 neighbour&#39;) # plt.plot(ema, label=&#39;mock Exponential Moving Average&#39;) # plt.legend() # plt.show() . . Well, as expected, exponentially moving average have some phase shift. It can be corrected with phase shift as described in adam paper. I am too lazy to implement it. hehe .",
            "url": "https://aungpaing98.github.io/blogs/numpy/notes/2021/07/07/Advanced-Numpy-PyData-Japan-19.html",
            "relUrl": "/numpy/notes/2021/07/07/Advanced-Numpy-PyData-Japan-19.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Basic Image Processing with Python",
            "content": "Image Acquisition . Images, taken from real life with camera, and then stored as the digital format in computer. In digital format, the images are represented by three color channel. (Red, Green and Blue). . In Python, we can read in the image with matplotlib library in following way : . img = matplotlib.image.imread(img_name) . After reading the image with above method, the variable img will contain the image value as the array in ndarray data type. We can also inspect the dimension(channel) of image in code with: . h, w, d = img.shape . 16, 16, 3 . As the above fig show, the mario image have 16 by 16 pixel values. So, h and w will be 16 x 16 and color image have 3 dimension. . Arithemetic Operations . Since Images are actually numbers, we could use functions to operate on the images. The most basic function would be adding, subtracting, multiplication and division. We will introduce Adding and Subtracting here in this blog post. . import matplotlib.image as mpimg import matplotlib.pyplot as plt import numpy as np import cv2 . # Helper Function for showing Images def imShow(imgs, titles=None): num = len(imgs) x = (num//4)+1 y = int(np.ceil(num/x)) plt.figure(figsize=(18,15)) for i in range(num): plt.subplot(x, y, i+1) cmap=None title=None if imgs[i].ndim==2:cmap=&#39;gray&#39; if titles!=None:title=titles[i] plt.imshow(imgs[i], cmap=cmap) plt.title(title,fontdict={&#39;fontsize&#39;:23}) plt.tight_layout() plt.show() . . Subtract Two Images . In the below Image, the subtracted result shows the difference between two images. . Note: While subtracting, we need to be careful of the data type range. Image arrays are typically in the range of 0 ~ 255. The data type is np.uint8. If it is negative value, it will subtract that negative value with 256. . Below show the example: . &#39;&#39;&#39;Because &#39;b&#39; is in the range of 0 ~ 255, while it exceed that value, it will subtract from 256. eg. here, &#39;b&#39; should be -5, so, it would be &#39;256-5 = 251&#39; &#39;&#39;&#39; a = np.array([5]) b = (a-10).astype(np.uint8) print(b) . . [251] . img1 = mpimg.imread(&#39;1.jpg&#39;) img2 = mpimg.imread(&#39;2.jpg&#39;) # First let&#39;s check their dimension assert img1.shape == img2.shape # Extend range so there won&#39;t be gibberish # diff = img2 - img1 diff = img2.astype(np.int16) - img1.astype(np.int16) diff[diff&lt;0] = 0 imShow([img1, img2, diff], [&#39;img1&#39;, &#39;img2&#39;, &#39;Difference&#39;]) . . Add Two Images . We can also add two images if they are in the same Dimension. . img1 = mpimg.imread(&#39;bird.jpg&#39;) img2 = mpimg.imread(&#39;back.jpg&#39;) h, w, d = img2.shape print(f&#39;Before resize : &#39;, img1.shape, img2.shape) img1 = cv2.resize(img1, (w, h)) print(f&#39;After resize : &#39;, img1.shape, img2.shape) add = img2.astype(np.int16) + img1.astype(np.int16) add[add&gt;255] = 255 imShow([img1, img2, add]) . . Before resize : (478, 717, 3) (421, 748, 3) After resize : (421, 748, 3) (421, 748, 3) . . Important: Both Adding and Subtracting two images need to have both same dimension for both inputs. . Geometric Transformations . Rotation, Crop . Rotation in the image is achieved by applying the transformation matrix to the image. | . M = cv2.getRotationMatrix2D((center_x, center_y), angle_to_rotate, scale) rotated = cv2.warpAffine(img, M, (x, y)) . Cropping is just simply Slicing of the image(numpy array). | . cropped = img[x_coor:x_coor, y_coor:y_coor] . # Rotation img = mpimg.imread(&#39;tower.jpg&#39;) h, w, d = img.shape simple = cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE) # More Flexible This Way M = cv2.getRotationMatrix2D((w/2, h/2), 90, 1) rotated = cv2.warpAffine(img, M, (h+100, w)) M = cv2.getRotationMatrix2D((w//2, h//2), 45, 0.5) rotated_ = cv2.warpAffine(img, M, (w, h)) imShow([img, simple, rotated, rotated_], [&#39;Tower&#39;, &#39;Simple Rotate&#39;, &#39;90 degree Rotated&#39;, &#39;45 degree Rotated&#39;]) . . # Crop [Image Slicing] img_copy = np.copy(img) door = img_copy[420:, 150:250, :] bicycle = img_copy[500:, 270:, :] imShow([img, door, bicycle], [&#39;Original Image&#39;, &#39;Door&#39;, &#39;Bicycle&#39;]) . . Color Image Transformation . RGB -&gt; BGR -&gt; HSV . Image can be converted to various color space by cv2.cvtColor(src, cv2.COLOR_). . Typically, if the image is read with matplotlib.image.imread(file_name), then it would read in with RGB format. And matplotlib.pyplot.imshow(img_array) would read the array as RGB format and display it. . While cv2.imread(file_name) would read in with BGR format and cv2.imshow() display as it take the array in BGR format. . Warning: read with matplotlib and plot with cv2 will result in Color space shift. . img = mpimg.imread(&#39;parrot.jpg&#39;) bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) imShow([img, bgr], [&#39;Original Image&#39;, &#39;BGR Image&#39;]) . . Unlike other color space, in HSV, the range for hue is from 0 ~ 179. . Hue value actually represent what we human understand of color. . eg. For red color, hue value would always be 0, regardless of the change in brightness and saturation. . img = mpimg.imread(&#39;parrot.jpg&#39;) hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) h = hsv[:, :, 0];s = hsv[:, :, 1];v = hsv[:, :, 2] print(&#39;hue t t&#39;, np.min(h), np.max(h), &#39; nsaturation t&#39;, np.min(s), np.max(s), &#39; nvalue t t&#39;, np.min(v), np.max(v)) imShow([h, s, v], [&#39;Hue&#39;, &#39;Saturation&#39;, &#39;Value&#39;]) . . hue 0 179 saturation 0 255 value 0 255 . Resizing Image . For the resizing, there are two cases: . Downsampling (Resized Image have lesser resolution than original One) | Upsampling (Resized Image have more resolution than original One) | . Also, there are many Interpolation methods to achieve resizing: . INTER_NEAREST (nearest-neighbour interpolation) | INTER_LINEAR (bilinear interpolation) | INTER_AREA (pixel area relation interpolation) [preferred for downsampling] | INTER_CUBIC (bicubic interpolation) | INTER_LANCZOS4 (lanczos interpolation) | . | . resized = cv2.resize(img, resized_dimension, interpolations=methods) . # Resizing img = mpimg.imread(&#39;lenna.png&#39;) h, w, d = img.shape dims = (w//2, h//2) dims_ = (w*2, h*2) downscale = cv2.resize(img, dims, interpolation=cv2.INTER_AREA) upscale = cv2.resize(img, dims_, interpolation=cv2.INTER_CUBIC) upscale_ = cv2.resize(img, dims_, interpolation=cv2.INTER_AREA) img = img[100:160, 100:160] downscale = downscale[50:80, 50:80] upscale = upscale[200:320, 200:320] upscale_ = upscale_[200:320, 200:320] imShow([img, downscale, upscale, upscale_], [f&#39;Original Image : {img.shape}&#39;, f&#39;Downscale Image : {downscale.shape}&#39;, f&#39;Upscale_cubic&#39;, f&#39;Upscale_area&#39;]) . . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Image Enhancing . Sometime, we get the image that is too dark or too bright, that it lose the information for the image. . For that, we could use transform in gray scale to hightlight the place in the image that we interest in. . The basic methods for that would be : . Negative | Log Transform | Gamma Transform | Contrast Stretching (Normalization) | Histogram Equalization | Here, we will focus on the first three method. . Note: Here, We show with just gray scale, But you can always try with all 3 Color spaces and stack them later with np.dstack((r, g, b)) if it is the color image. . Negative . Effect : Bright region turn to dark and dark region turn to bright.(invert of image). . Equation : $$y = 255-x$$ . Log Transform . Effect : Add brightness to where the image is dark. . Equation : $$y = log(c+x)$$ where : $c$ = constance, $x$ = Normalized pixel . Code : . # Normalized Image x = x/255 y = np.log(c + x) . Gamma Transform . Effect : Adjustable change in brightness with gamma value. . Equation : $$y = x**r$$ where : $r$ = gamma . Code : . # Normalized Image x = x/255 y = x**r . img_names = [&#39;bird.jpg&#39;, &#39;F3.jpg&#39;, &#39;PCL.jpg&#39;, &#39;cells.jpg&#39;, &#39;tree.jpg&#39;] for img_name in img_names: img = mpimg.imread(img_name) if img.ndim&gt;=3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) negative = 255-img img_copy = np.copy(img).astype(np.float32) img_copy /= 255 log = np.log(1.0+img_copy) # imShow([img, negative, log], [&#39;Orignal Image&#39;, &#39;Negative Image&#39;, &#39;Log Image&#39;]) imShow([img, negative, log], [&#39;Orignal Image&#39;, &#39;Negative&#39;, &#39;Log Image&#39;]) . . And Gamma correction with difference gamma value : . gamma0 = 0.5 gamma1 = 1 gamma2 = 1.5 img = mpimg.imread(&#39;tree.jpg&#39;) if img.ndim&gt;=3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) r0 = 1/gamma0 result0 = (img/255)**r0 r1 = 1/gamma1 result1 = (img/255)**r1 r2 = 1/gamma2 result2 = (img/255)**r2 imShow([img, result0, result1, result2], [&#39;original image&#39;, f&#39;gamma value : {gamma0}&#39;, f&#39;gamma value : {gamma1}&#39;, f&#39;gamma value : {gamma2}&#39;]) . . As Gamma value increase, the image get brighter. . Image Gradient . Edge Detection . Edge detection is the process of finding the boundaries (shape) of objects in the image. It works by detecting the change in pixel value in the image. . There are many ways to find the edge in the image. Mainly difference in the filter. Here, we will introduce two mostly used filter. . Sobel Filter (L1)sobel = cv2.Sobel(img, filter_size, dx, dy) . | Laplacian Filter (L2)laplace = cv2.Laplacian(img, cv2.CV_64F, ksize) . | After finding the edge, we could also use that to sharpen(enhance the edge) the image. So, we could Smooth (Blur) the image and sharp the image. . Smoothing (Blurring) Image . Commanly used method: . Gaussian Filterblurred = cv2.GaussianBlur(img, filter_size(tuple), std) . | Median Filter (Used to filter salt noise) . blurred = cv2.medianBlur(img, filter_size(int)) . Belowing show the Difference in Edge detection Method. . | def sobelEdge(img): sobelx = np.abs(cv2.Sobel(img, 3, 0, 1)).astype(np.uint32) sobely = np.abs(cv2.Sobel(img, 3,1, 0)).astype(np.uint32) sobel = np.sqrt(np.square(sobelx) + np.square(sobely)) sobel = (sobel/np.max(sobel)) * 255 return sobel.astype(np.uint8) def laplaceEdge(img): laplace = np.abs(cv2.Laplacian(img, cv2.CV_64F, ksize=3)) laplace = ((laplace/np.max(laplace)) * 255).astype(np.uint8) return laplace img_names = [&#39;dark.jpg&#39;, &#39;page.jpg&#39;,&#39;tower.jpg&#39;] for img_name in img_names: img = mpimg.imread(img_name) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) sobel = sobelEdge(gray) laplace = laplaceEdge(gray) imShow([gray, sobel, laplace], [f&#39;Original image{img.shape}&#39;, f&#39;Sobel{sobel.shape}&#39;, f&#39;Laplacian{laplace.shape}&#39;]) . . And the result of Smoothing and Sharpening of images. . def smooth(img): blurred = cv2.GaussianBlur(img, (9,9), 1) return blurred def sharp(img): blurred = cv2.GaussianBlur(img, (5, 5), 1).astype(np.float32) img = img.astype(np.float32) result = np.abs((1.5*img) - (0.5*blurred)) result = ((result/np.max(result)) * 255).astype(np.uint8) return result blurred = smooth(gray) sharped = sharp(gray) door = gray[420:, 150:250] door_blurred = blurred[420:, 150:250] door_sharped = sharped[420:, 150:250] imShow([gray, blurred, sharped, door, door_blurred, door_sharped], [&#39;Original Image&#39;, &#39;Smoothed Image&#39;, &#39;Sharped Image&#39;, &quot;Original Door&quot;, &#39;Blurred Door&#39;, &#39;Sharped Door&#39;]) . . Image Segmentation . The image show in plt.imshow() typically take three types of range. . uint8, range from (0~255)[total of 256 level] | float64, range from (0~1)[total of many floating level]&lt;eg. 0.1, 0.11, 0.111&gt; | Binary Image, contain only (0 and 1)[2 level]&lt;0 mean dark and 1 mean light&gt; | . Usually, we use binary image in Mask. . 1 mean object and 0 mean background. . # Gray Scale Image img1 = np.array([[0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255]]) # Binary Image img2 = np.array([[0, 1, 1, 1, 1, 1], [0, 0, 1, 1, 1, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1]]) imShow([img1, img2], [&#39;Gray scale Image&#39;, &#39;Binary Image&#39;]) . . For the thresholding, two methods can be used. . Global Thresholding (one threshold value for all region in the image) | Typically, we set the threshold value to random number, or we find the best threshold value by trial and error. Or we can use **otsu** method, which find the optimized threshold value from intensity histogram of image. . Adaptive Thresholding | Since the lighting condition in different region in a single image can be different, Adaptive thresholding method is often better than global method. . Adaptive threshold use difference threshold value in different region. . # Global Threshold img = mpimg.imread(&#39;page.jpg&#39;) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # 0 ~ 255 gray = cv2.medianBlur(gray, 5) glob_thresh = np.ones_like(gray) glob_thresh[gray&lt;25] = 0 # 0 &amp; 1 adap_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 3) _, otsu_thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) imShow([gray, glob_thresh, otsu_thresh, adap_thresh], [&#39;gray&#39;, &#39;global_threshold&#39;, &#39;otsu_Threshold&#39;, &#39;Adaptive_threshold&#39;]) . . Since thresholding process is transforming gray scale image to Binary one, it is also called binarization. . Different method for thresholding would be useful in different scenerios.The best way to find the best method is by trial and error. . For example, althought gobal thresholding method may not give better result than adaptive one, but its speed is faster casue there is not need to find the threshold value, by assigned by the user. . Morphological Transformations . Morphological transform is the transformation of shape in the binarization image. Typically used to modify the Mask (Binary Image). . Mostly Used methods are called: . Erosion (Reduce Shape) | Dilation (Expand Shape) | And the combination of these methods evolved to: . Opening (Disconnect closely related part) | Closing (Connect closely related Part) | img = mpimg.imread(&#39;cells.jpg&#39;) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) gray = cv2.medianBlur(gray, 5) gray = gray[30:, :] # Let&#39;s do some thresholding thresh = np.zeros_like(gray) # threshold value here get by trial and error thresh[gray&gt;175] = 1 kernel = np.ones((5,5), np.uint8) #Erosion eroded = cv2.erode(thresh, kernel, iterations=1) #Dilation dilated = cv2.dilate(thresh, kernel, iterations=1) # Opening (Erosion + Dilation) opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel) # Closing (Dilation + Erosion) closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel) imShow([gray, thresh, eroded, dilated, opening, closing], [&#39;Gray Scale Image&#39;, &#39;Binary Threshold Image&#39;, &#39;Eroded Image&#39;, &#39;Dilated Image&#39;, &#39;Morpho Open&#39;, &#39;Morpho Close&#39;]) . . In Opening, the method open(separate) the closely connected part. Opening is achieved by first erosion, then dilation. . In Closing, the method close(connect) the closely connected part. Closing is achieved by first dilation, then erosion. . thresh_ = thresh[100:200, 150:250] open_ = opening[100:200, 150:250] close_ = closing[100:200, 150:250] imShow([thresh_, open_, close_], [&#39;Original Binary&#39;, &#39;Opeing&#39;, &#39;Closing&#39;]) . . Conclusion . The Above mentioned methods are all just basic image processing techniques. There are certainly many more state of the art algorithms. . But, If we get the idea that image are numbers and various functions could be apply to the image, then, we could modify and create intereting projects in computer vision. .",
            "url": "https://aungpaing98.github.io/blogs/image_processing/overview/2020/11/22/image_processing_overview.html",
            "relUrl": "/image_processing/overview/2020/11/22/image_processing_overview.html",
            "date": " • Nov 22, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "CS50 Study Note",
            "content": "Notes . This notebook is referenced from the CS50 course conducted by MIT lectures online from youtube. The course can be found in this youtube link. . Previews . My programming jorney starts from 3 years ago, when I first learn Python from youtube. It is a easy programming compare to others. Before that, I have attended lectures from university for basic comptuer science in C++ language. It was not a very productive one. And after I learnt Python, it is superficial, I now know that, to get the best performance of the algorithms, I need to know the logic behind all the pre-built function. That is why I started learning this course. . CS50, this lecture is really one of the top in my favorate list from my learning jorney. The lectures is energetic, explaning the lowest detail of the programming. I wish I have seen this lecture sooner. . Lectures 1 - C . The lecture is mainly conducted with using C langauge in first 5 lectures of the course. C language is the low level language meaning we can get the best performance in speed compare to other languages if the algorithms is optimized. . Good coding practice . To get the most efficient code, meaning it is functionable, able to get the desired output, it have a good design, most efficient and it have a good style, so everyone can understand the code. . $$ Code begin{cases} quad text{Functionable} quad text{Design} quad text{Style} end{cases} $$Command Line Interface (CLI) and Graphic User Interface (GUI) . Developer often use command line (terminal in mac) to execute the program. CLI is less user friendly than GUI, it needs a bit more knowledge but it is hackable and origin. The terminal is a platform which we can use complier to compile the code to machine code and open that machine code to get the output of the program. . So, the typical process is, . Write the code with text editor (visual studio code, atom, etc) | Compile the code in terminal with compiler and output machine code. | Run the machine code and output the result in terminal. | . Compiler is the program that is pre-written to convert the code that we write to machine code, that the computer understand. Different language have different compiler. And in mac, we need to install X-Code to run C program cause X-code is the compiler that contain multiple languages including C. .",
            "url": "https://aungpaing98.github.io/blogs/computer_science/basic/algorithms/2020/02/22/CS50.html",
            "relUrl": "/computer_science/basic/algorithms/2020/02/22/CS50.html",
            "date": " • Feb 22, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Lecture 7 | Training Neural Network 2",
            "content": "Recap . In The previous lesson, we introduced the basic operation of convolution. Because the input is normalized between (-1, 1), so the effect of filter on the input will result on activating the area where the input is similar to the filter. That is the effect of convolution. . Training Model . The overall process of getting a DNN model include, collect data, construct model, train model and evaluate model. In the training part, we have to optimize the model to get better performance. The esscent of optimizing the model is update the weight parameter to get lesser loss value. This is done by optimizer. In the last time, we introduced vanilla gradient descent. By the rate of update according to the use of dataset, it can be further named as: . Name Update per datapoint Number of datapoints in dataset . SGG (Stochastic Gradient Descent | Update weight for each data point) eg. 1 | 100,000 | . Mini-Batch GD (Mini-batch Gradient Descent | Update weight for small batch of data point) eg. 100 | 100,000 | . GD (Gradient Descent | Update weight once for all data point) eg. 100,000 | 100,000 | . There are many more optimizer nowaday and most popular one would be Adam Optimizer, which will be introduced later. . Activation Functions . Sigmoid Function . Sigmoid function, also called Logistic function, have a “S” continuous function with output range from 0 to 1. The equation for the sigmoid function is as following: σ(x)=11+e−x sigma(x) = frac{1}{1 + e^{-x}}σ(x)=1+e−x1​ and the derivative(graident) of sigmoid function is: σ(x)[1−σ(x)] sigma(x)[1- sigma(x)]σ(x)[1−σ(x)] . 3 Problems with Sigmoid . Saturated neurons kill the graident. | Sigmoid output are not zero center. | exp() function is expensive to calculate. | . Since sigmoid output are always positive(not zero center), if we concatenate many cells and its input are from another cell output, it will only get positive value as input. That is why sigmoid, not zero center is bad. . Instead, we will use tanh activation, which have the advantages of zero center and keep range between (-1, 1). But it still get saturated at the end and kill the gradient. . Relu (Rectified Linear Unit) . Most popular activation function now is Relu activation, which is simple, and not saturate at (+) region. And practice show it converges much faster than other activation functions. . The equation of Relu is as follow: Relu(x)={xif x&gt;00if x &lt; 0Relu(x) = begin{cases} x &amp; quad text{if x&gt;0} 0 &amp; quad text{if x &lt; 0} end{cases}Relu(x)={x0​if x&gt;0if x &lt; 0​ And the differentiation equation is as follow: Relu(x)={1if x&gt;00if x &lt; 0Relu(x) = begin{cases} 1 &amp; quad text{if x&gt;0} 0 &amp; quad text{if x &lt; 0} end{cases}Relu(x)={10​if x&gt;0if x &lt; 0​ Althought relu also saturate at $-$ size of the output, it is much easier to compute and simple, and it works. So, in the hidden layers of Neural Network, we often use Relu as the first choise for activation function. . Aside from Relu, there are many other activation functions: . Leaky Relu : $f(x) = max(0.01x, x)$ | Exponential Linear Unit | Maxout Neuron : $max(w^T_1x + b_1, w^T_2x + b_2)$ | . Data Preprocessing . This include Normalization of data, dimemsion reduction with PCA or T-SNEA if needed and other feature engineering method. . Weight Initialization . Q: What will happen if all weight is initialized with 0? Cause there is loss value, there will the gradient flow. But, casue the input value is all zero, coming from previous input * weight, it the gradient flow will get kill and the model will not get update. . . The above figure show the output filter from initializing the model with random values of $W = 0.01 * np.random.randn(D, H)$. Since the output value range from -1 to 1 and the weight value is small, the output is getting smaller and smaller everytime. And the result in output getting closer to 0. The main problem is weight initialization value is too small. What happen if we increase that random initialization value $W = 1 * np.random.randn(D, H)$. . To solved this, we generally use Xavier initialization method. . Batch Normalization . The idea is that we want middle layers in network to get gaussian distribution too, so we will just get output from activation map and normalize its value. And that is called Batch Normalization. It get the following advantages: . Improve gradient flow through the network | Allow higher learning rate | Reduce strong dependence on weight initialization | A little regularization effect. | . Babysitting Training . Tips . Always do sanity check of model architecture before training. | When first train, train a small portion and make sure the model can overfit. If so, retrain with all dataset. | When training, set learning rate to low but not too low and observe result. | . Hyper-parameters Optimization . Cross Validation Strategy . Coarse -&gt; Fine First, try just a few epoch with certain hyper parameters, then try another. If the duration of one hyperparameter getting to converge is about 3 times longer, try another one. And it is better to optimize in Log space. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture7/",
            "relUrl": "/cs231n-lecture7/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Lecture 6 | Training Neural Network 1",
            "content": "Recap . In The previous lesson, we introduced the basic operation of convolution. Because the input is normalized between (-1, 1), so the effect of filter on the input will result on activating the area where the input is similar to the filter. That is the effect of convolution. . Training Model . The overall process of getting a DNN model include, collect data, construct model, train model and evaluate model. In the training part, we have to optimize the model to get better performance. The esscent of optimizing the model is update the weight parameter to get lesser loss value. This is done by optimizer. In the last time, we introduced vanilla gradient descent. By the rate of update according to the use of dataset, it can be further named as: . Name Update per datapoint Number of datapoints in dataset . SGG (Stochastic Gradient Descent | Update weight for each data point) eg. 1 | 100,000 | . Mini-Batch GD (Mini-batch Gradient Descent | Update weight for small batch of data point) eg. 100 | 100,000 | . GD (Gradient Descent | Update weight once for all data point) eg. 100,000 | 100,000 | . There are many more optimizer nowaday and most popular one would be Adam Optimizer, which will be introduced later. . Activation Functions . Sigmoid Function . Sigmoid function, also called Logistic function, have a “S” continuous function with output range from 0 to 1. The equation for the sigmoid function is as following: σ(x)=11+e−x sigma(x) = frac{1}{1 + e^{-x}}σ(x)=1+e−x1​ and the derivative(graident) of sigmoid function is: σ(x)[1−σ(x)] sigma(x)[1- sigma(x)]σ(x)[1−σ(x)] . 3 Problems with Sigmoid . Saturated neurons kill the graident. | Sigmoid output are not zero center. | exp() function is expensive to calculate. | . Since sigmoid output are always positive(not zero center), if we concatenate many cells and its input are from another cell output, it will only get positive value as input. That is why sigmoid, not zero center is bad. . Instead, we will use tanh activation, which have the advantages of zero center and keep range between (-1, 1). But it still get saturated at the end and kill the gradient. . Relu (Rectified Linear Unit) . Most popular activation function now is Relu activation, which is simple, and not saturate at (+) region. And practice show it converges much faster than other activation functions. . The equation of Relu is as follow: Relu(x)={xif x&gt;00if x &lt; 0Relu(x) = begin{cases} x &amp; quad text{if x&gt;0} 0 &amp; quad text{if x &lt; 0} end{cases}Relu(x)={x0​if x&gt;0if x &lt; 0​ And the differentiation equation is as follow: Relu(x)={1if x&gt;00if x &lt; 0Relu(x) = begin{cases} 1 &amp; quad text{if x&gt;0} 0 &amp; quad text{if x &lt; 0} end{cases}Relu(x)={10​if x&gt;0if x &lt; 0​ Althought relu also saturate at $-$ size of the output, it is much easier to compute and simple, and it works. So, in the hidden layers of Neural Network, we often use Relu as the first choise for activation function. . Aside from Relu, there are many other activation functions: . Leaky Relu : $f(x) = max(0.01x, x)$ | Exponential Linear Unit | Maxout Neuron : $max(w^T_1x + b_1, w^T_2x + b_2)$ | . Data Preprocessing . This include Normalization of data, dimemsion reduction with PCA or T-SNEA if needed and other feature engineering method. . Weight Initialization . Q: What will happen if all weight is initialized with 0? Cause there is loss value, there will the gradient flow. But, casue the input value is all zero, coming from previous input * weight, it the gradient flow will get kill and the model will not get update. . . The above figure show the output filter from initializing the model with random values of $W = 0.01 * np.random.randn(D, H)$. Since the output value range from -1 to 1 and the weight value is small, the output is getting smaller and smaller everytime. And the result in output getting closer to 0. The main problem is weight initialization value is too small. What happen if we increase that random initialization value $W = 1 * np.random.randn(D, H)$. . To solved this, we generally use Xavier initialization method. . Batch Normalization . The idea is that we want middle layers in network to get gaussian distribution too, so we will just get output from activation map and normalize its value. And that is called Batch Normalization. It get the following advantages: . Improve gradient flow through the network | Allow higher learning rate | Reduce strong dependence on weight initialization | A little regularization effect. | . Babysitting Training . Tips . Always do sanity check of model architecture before training. | When first train, train a small portion and make sure the model can overfit. If so, retrain with all dataset. | When training, set learning rate to low but not too low and observe result. | . Hyper-parameters Optimization . Cross Validation Strategy . Coarse -&gt; Fine First, try just a few epoch with certain hyper parameters, then try another. If the duration of one hyperparameter getting to converge is about 3 times longer, try another one. And it is better to optimize in Log space. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture6/",
            "relUrl": "/cs231n-lecture6/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Lecture 5 | Convolutional Neural Network",
            "content": "A bit of history . In around 1957, Frank Rosenblatt, implemented the first perceptron machine named Mark I Perceptron. The machine was connected to a camera that used 20x20 cadmium photocells to produce 400-pixel images, and recognize the letter of alphabet with function: f(x)={1if w . x + b &gt;00otherwisef(x) = begin{cases} 1 quad text{if w . x + b &gt;0} 0 quad text{otherwise} end{cases}f(x)={1if w . x + b &gt;00otherwise​ . With the update rule of: wi(t+1)=wi(t)−α(dj−yj(t))xj,iw_i(t+1) = w_i(t) - alpha (d_j - y_j(t))x_{j, i}wi​(t+1)=wi​(t)−α(dj​−yj​(t))xj,i​ . Seems familiar, isn’t it. It is the same with the perceptron we are working with. . Which, in 1960, was modified with increasing the number of inputs and adjustable bias value by Widrow and Hoff. . And it was at 1986, Rumelhart et al, many layers perceptrons was tried with complete backpropagatoin method. . And in 2006, Hinton and Salakhutdinov, did some reinvigorated research in Deep Learning and with fine tunning with backpropagation, they achieved a great result. . Finally, at 2012, there is a breakthrough with ImageNet dataset with AlexNet (Convolutional Neural Network). . Although it is AlexNet which have a breakthrough, its base model architecture already exists since 1998, the year I was born, by the model LeNet-5 developed by LeCun, Bottou, Bengio, Haffner. But due to the lack of calculation power and dataset, they did not get quite the result. . And the modern study of biological on human vision system state that our vision system is composed of main three types of cells. . Simple cells : Response to light orientation. | Complex cells : Response to light orientation and movements. | Hypercomplex cells : response to movement with an end point. | . Fast-forward to Today: ConvNet are Everywhere . With the advanced in hardward like GPU, and the explosive of dataset from the internet, ConvNet are everywhere in our daily life. It got applied from simple tasks like Image Classification, Object Detection, Semantic Segmentation to Image Captioning. And it is also popular in the field of anomaly detection for automation tasks. . There are also many fileds in which ConvNet are involved with. Transportation, Astrophysis, Movie and multimedia and so on. . Fully Connected Layers . Back when we do not use ConvNet, we will first need to flatten the image. Then connect each input with a weigth value. For example, if the input image have dimension of 32, 32, 3, then after flatten it will be 32 * 32 * 3 = 3072, and the weight will have 3072 * 10 to output a value of 10. This is only one layer and the spatial information is not preserve in this case. While in fully connected, we will need large weigth size to cover the whole image, we can use filter in convolutional layers to cover the image too. . Also, to understand convolutional operations: . Remember, when doing a convolution operation, its dimension get reduced at each side. So, to calculate the output size of the feature map, we can use the equation of: O=I+2PS+1O = frac{I + 2P}{S} + 1O=SI+2P​+1 . Pooling Layers . Pooling operation in the ConvNet have the effect of reducing the feature size of each output from the activation function, and is called the downsampling. It is a commonly used method as it can reduce the memory size and calculation size for the model. Typical pooling methods include: . Max Pooling with (2, 2 filter and 2, 2 stride) | Average Pooling (2, 2 filter and 2, 2 stride) | Strided Convolution (3, 3 filter and 2, 2 stride) | . Training online and visualization of Model Architecture. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture5/",
            "relUrl": "/cs231n-lecture5/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Lecture 4 | Backpropagation and Neural Network",
            "content": "Backpropagation . recursive application of the chain rule along a computational graph to compute the gradients of all inputs/parameters/intermediates Lecture Note. . The basic vanilla model optimization method is called gradient descent, where the gradient of loss respect to weight get descent everytime we update the model parameters. The equation is as follow. Wt=Wt−1−αdLdWt−1W_{t} = W_{t-1} - alpha frac{dL}{dW_{t-1}}Wt​=Wt−1​−αdWt−1​dL​ In code: . # vanilla Graident Descent while True: # loss_fun to calculate loss from data with respect to weigth. weight_grad = evaluate_gradient(loss_fun, data, weight) weight += -step_size * weight_grad . In mathematical term, this is called analytic gradient. They provide an example backpropagation process with simple computational graph. . . From the graph, we can see the result gradient from two simple operations, addition and multiplication. Addition in local gradient backpropagation will simply return the previous gradient. While in multiplication, local gradient is the same as the other input. So, imagine, normally, we would calculate $dW_{t}$, which will have the graident of $X_{t}*dX_{t+1}$. If we use Relu as the activation function in the intermediate layers: . $X$ $W$ $Relu(W^T X)$ $dW_{t}$ . + | + | Positive | 1 | . + | - | Negative | 0 | . - | + | Negative | 0 | . - | - | Positive | 1 | . 1 in above table result in $X_t * Relu(W^T X)$ of gradient. . Local Gradient . When the model get too deep, many layers, it is hard to calculate all the computation flow. Instead, we calculate for each local gradient and compile them. Local gradient have the equation of $ frac{d relu(W^T * X)}{dX}$ for each weigth parameter. . . As mentioned earlier, add gate will result in the previous gradient value, multiplication gate will swap the gradient with another input.So . Add Gate : Gradient Distributor | Max Gate : Gradient Router | Mul Gate : Gradient Switcher | . Size of Gradient . The size of the graident is the same or larger than the size of weight parameters. Cause it also have to store the gradient value of the output from the activation function. . Model Architecture . In the deep learning papers, we often see the authors describe their layers as 34 layers, 56 layers, and so on, often this refer to how many weight layers exists in the model. . .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture4/",
            "relUrl": "/cs231n-lecture4/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Lecture 3 | Loss Function and Optimizatoin",
            "content": "Loss Function . In the previous lesson, when we use a KNN model, we use L1 distance or L2 distance to measure the similarity between two images. The lower the value, the similar the two images are. It, in other way, can be seems as the loss function between two element, large the value mean larger loss. In this lecture, different loss functions will be introduced. In the esscence, loss value tell us how badly the model is performing. The loss function take in the output from the model and compare it with the training label. If similar, loss value is small, if not, loss value is large. General loss function can be expressed as: L=1N∑iLi(f(xi,W),yi)L = frac{1}{N} sum_i L_i(f(x_i, W), y_i)L=N1​∑i​Li​(f(xi​,W),yi​) In the lecture, one particular loss was introduced, even thought it is not of much used in later tutorial. Multi-class SVM Loss (Hinge Loss): Li=∑j≠yimax(0,sj−syi+1)L_i = sum_{j neq y_i} max(0, s_j - s_{yi} + 1)Li​=∑j​=yi​​max(0,sj​−syi​+1) Basically, the loss is computed from the non-normalized probability distribution of the model output. For each class, it calculate the relative difference between the true label and other class probability. The main drawback is because it is non-normalized, the loss can be hard to controlled(if the model output probability is ranging into large value), it can state problem. In the above case, the loss value will not change even if the probabily for car input is drop to 3.0. . Q1. What happened to loss if the car scores changed a bit? My Ans: The car score can drop to 3.0 and not make loss change. . Q2. What is the min/max possible loss? My Ans: min : 0, max : can be any to infinity. . Q3. At initialization, W is small, so all $s approx 0$. What is the loss? My Ans: There will still be some loss, defined by biased term +1 in loss function. So, if it is 10 class classification, it will probably get loss value of 10 in the very first iteratin. . Q4. What if the sum was over all classes? (including (j=y_i )) My Ans: question not quite understand. . Q5. What if we used mean instead of sum? My Ans: There will still be loss when there is loss. The value will just be smaller. . Q6. What if we use : Li=∑j≠yi(max(0,sj−syi+1))2L_i = sum_{j neq y_i} (max(0, s_j - s_{yi} + 1))^2Li​=∑j​=yi​​(max(0,sj​−syi​+1))2 My Ans: There will still be loss when there is loss. The value will just be bigger. And because there is no negative loss value, so, it will just simple make loss value bigger. . In the presentation also stated that, hinge loss is no good, because it is not normalized. weights value does not need to be unique to get loss to zero. . Regularization . Regularization in the model take the effect of making the model less variance, prevent over-fitting. By adding penelties to the loss function, it essentially turn of some of the neurons, making the model less complicated. . Occam’s Razor: Among competing hypotheses, the simplest is the best. . It get the following equation: L=1N∑iLi(f(xi,W),yi)+λR(W))L = frac{1}{N} sum_i L_i(f(x_i, W), y_i) + lambda R(W))L=N1​∑i​Li​(f(xi​,W),yi​)+λR(W)) . Typically used regularization methods are: . L1 and L2 regularization (Weight Decay). | Dropout / DropBlock. | Batch Normalization, Stochastic Depth. | Data Augmentation. | . L2 Regularization (Weight Decay) . It get the following equation: L=1N∑iLi(f(xi,W),yi)+λ∑k∑lWk,l2L = frac{1}{N} sum_i L_i(f(x_i, W), y_i) + lambda sum_k sum_l W^2_{k, l}L=N1​∑i​Li​(f(xi​,W),yi​)+λ∑k​∑l​Wk,l2​ To reduce loss value, the function need to reduce the weight value, result in turning some of the weight neuron off, resulting in simpler model. . Softmax Classifier (Multiclass Logistic Regression) . Remember the linear logistic regression which we use sigmoid function as activation, get output from sigmoid and calculate loss with $- hat{y}log(y)$. That is for binary classification. . While in multi-class classification, we will use Softmax to normalize the output from model, and calculate loss with $- hat{y}log(y))$, same as linear logistic regression. This solve the problem with hinge loss, as it does not consider normalizing the output from the model first to calculate the loss. The softmax function is as following: P(Y=yi∣X=xi)=esk∑jeskP(Y=y_i|X=x_i) = frac{e^s k}{ sum_j e^s k}P(Y=yi​∣X=xi​)=∑j​eskesk​, it normalized the output from model. . Q1. what is the min/max possible loss $L_i$? My Ans: min: very small, but never 0. max : not very large. for 10 classes, max loss would be around 60. . Q2. At initialization, W is small, so all (s approx 0 ). What is the loss? My Ans: since all s is the same, for 10 classes, it will get probability of 0.1 for each class. The loss might be 1, if log is based 10 and only consider one class for loss. But I guess, the loss look at all 10 classes when calculating loss, Check needed. . Short Exercise: . Assume Score Class Hinge Loss Softmax Loss . [10, -2, 3] | 0 | 0 | median loss | . [10, 9, 9] | 0 | 0 | largest loss | . [10, -100, -100] | 0 | 0 | smallese loss | . Recap: . We learnt the score function and loss function. Now we want to use loss function to update the weight value. But how? This step of taking the loss value to update the weight to get less loss is called optimization. Optimization is done by doing backward progation throught the network, which basically is chaging the weight value to reduce the loss. . Note: You may not understand how this work, cause this course focus on computer vision. Later, I will post more note about how model is updated to get low loss. . When doing gradient update, there are basically two ways: . Numerical Gradient, by changing the small amount of independent variable (W in this case), see how that change in dependent variable (L in this case). slow, inefficient | . | Analytic Gradient, by using equation, we can calculate the gradient from the input. fast, exact. | . | . Image features . Image in a computer can take large space. And thus using it for learning also take more computation power. So, instead of just using image as the input, we often tend to change the image into different features, like simple histogram of the image, HOG(Histogram of Oriented Gradient) of the image or Bag Of Words, and etc. These methods greatly reduce the input size and computation needed while not losing any information for the image. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture3/",
            "relUrl": "/cs231n-lecture3/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Lecture 2 | Image Classification Pipeline",
            "content": "Core Tasks in Comptuer Vision . Image Classification | Semantic Segmentation | Object Detection | Instance Segmentation | . The problem in computer vision is that when reading in images to computer, what computer see is actually color bits representing RGB value. So, a slight change in the image can make huge different. That is called the semantic gap. . Challenges . Below are the chanllenges that could change the value of the image even if the object in the image is the same. . ViewPoint variations (Camera View point change) | Illumination (Lighting condition of image) | Deformation (Shape of Object in the image changed) | Occlusion (background object get blocked by object in front) | Background Clutter (Color of object the same as background, eg. fox in snow) | Intraclass variation (Various intra class in object. eg. bulldog and akita) | . Attempts have been made . Input : Image Process : Find edge, Convolute with template Output : Match -&gt; is cat, else –&gt; not cat. . Data-Driven Approach . Collect Datasets. | Use ML to train a classifier (Data Model). | Evaluate with ML model. | . 1. Use NN (Nearest Neighbour) . Given a test image, compare it with all images from the train dataset, find the closest one, its label is the test label. Loss function : $L = sum_p |I_1^P - I_2^P|$, Just subtract two images and sum the difference. . 2. Use KNN (K-Nearest Neighbour) . Instead of just the closed one, it select the k closed one. Majority of the k label is the test label. For example, Nearest Neightbour would be 1-NN, where the number of closest neighbour is set to 1. . L1 Loss and L2 Loss . As shown in the figure above, 3 elements with respect to the target will get difference loss value if different loss function was used. . In the course, he mentioned that if the input data is dimension aware, it should use L1 Loss. But commonly, most people choose L2 as their loss. Cause the relative distance between two points is the same in L2 Loss. Intuiative Playground for KNN by Standford . Setting Hyperparameters . In the above case, k-value is the hyperparameters, we won’t know which k-value will give out the best performance. So, we will divide the dataset to give us which hyperparameters should be used. . Train Dataset : The dataset to train our model. | Validation Dataset : The dataset used for validation. | Test Dataset : The dataset used for evaluation of model. | . If we split the dataset in such three fold, we can train the model, improve model by testing different hyper parameters on validation set, and test and give performance of the model on test dataset. Backthen, when there are no much datasets available, we use cross-validation method, which split data into folds, train and validation on each fold and average the result. It is not much used in deep learning nowaday. Just because there is no need. . Note: In real life, KNN on image will never be used. It is too slow on test time, memory inefficient and Loss algorithm is not good. . Linear Classification . Parametric Approach . Collect Datasets. | Use ML to train a classifier (Parametric Model). | Evaluate with ML model. | . . The difference between data-driven approach and parameteric approach is that the model in previous one try to memorize the dataset, while the later train the parameters $(W, b)$ in the model. This way, the model is robust to inputs and the model can be trained to get better performance with more dataset. . Interpreting a Linear Classifier . The course present an interesting way to interpret the model. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture2/",
            "relUrl": "/cs231n-lecture2/",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition",
            "content": "History of Vision . It was now known that around 543 millions years ago, the evolution of the organisms in earth began. Large and vast species of evaluations happened in next short 10 millions years. There is an interesting hypothesis now for the case of this event, it is that around such time, the organisms start to evolve eyes. With eyes, they got vision, and they start moving in directions where there is food. And such, evolution began. . The start of Everything, Camera . The advance in modern vision start from the camera, at first, most cameras are pinhole cameras, the below list these cameras: . Gemma Frisius, 1545 | Encyclopedia, 18 Century | Leonardo Da Vinci, 16 Century | Nowadays, almost everyone get a cellphone and these cell phones are providing image data every day. So, the dataset available these days are much more compared to the older one. Modern Cameras can also get images of high resolutions and this also Challenge the computation power of the processor. . Breakthrough in Biologists . It is now known that around 50% of neurons in human brain are involved in visual system. The famous experiment, Hubel and Wiesel done in 1959, demostrated that a cat’s brain responds to the stimuli by activating specific neurons in the brain. . First Computer Vision Paper . The very first computer vision paper came at 1963 by Larry Roberts. . Block World, Larry Roberts, 1963 | Generalized Cylinder, 1973 | Pictorial Structure, 1973 | David Lowe (Edge World), 1987 | Problems To Tackle in Computer Vision . The very famous computer vision project at the 1966, called the summer projects, which main goal is to make an AI that could have vision just like human could. It is still quite a challenging task for nowadays, let alone that time, have no computational power and data. They failed and came the first AI winter. The computer vision now, mostly focus on one features and increasing the accuracy for that feature. The basic problems in computer vision are: . Image Segmentation (Shi, Jinbo, Mailk, 1997)[Graph Theory] | Face Detection (Voila &amp; Jones, 2001)[Adaboost] | “SIFT” &amp; Object Detection (David, 1999) | Spatial Pyramid Matching | Histogram of Gradients (HoG) (2006) | Deformable part model (2009) | Publish Datasets for Pushing Computer Vision to beyond. . The publish datasets help researchers to benchmark their models and gain publish datasets with ease. Modern deep learning models requires large amount of datasets to train. And such, quality labelled datasets are like the fuel for the model. The famous datasets include: . MNIST Dataset (Handwritten digits) | PASCAL Visual Object Challenge | ImageNet Large Scale Visual Recognitions Challenge | Evolution of Image Classification Algorithms . The very top algorithms for computer vision is Convolutional Neural Networks, where it use convolutions layers as the neural layers to extract the image information. The very first breakthrough in Computer Vision using deep learning is at 2012, where AlexNet was introduced in ImageNet Challenge. But, AlexNet was not done in overnight. Before AlexNet, there is already a CNN model built similar to AlexNet, in 1998, LeCun introduced a model but not achieved best accuracy because of the hardware and lack of dataset. .",
            "url": "https://aungpaing98.github.io/blogs/cs231n-lecture1/",
            "relUrl": "/cs231n-lecture1/",
            "date": " • Jan 12, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Notes from Advanced Numpy (Scipy Japan 2019)",
            "content": "Abstrast . &quot;Scipy Japan 2019&quot;is the 18th annual Scientific Computing with Python conference. This note is taken from the &quot;Advanced Numpy&quot; topic, speech by Juan Nunez-Iglesias. The source code for speech is available at github. . I came across this on youtube. The speech give some aspect of Numpy that I am getting confused before, so, this notebook helps me to get more hand on Numpy. Let&#39;s get started. . A Little Introduction to DNA and RNA . The author is originally from the biologist background, so he introduced some ideas about DNA and RNA. Althought it is not much relevent to the subject, it is nice to know new things. . . Difference between List and Numpy Array . When we defind a variable in list, the true value of each element in the list is the pointer, which point to the location in hardware about where the value is stored. And each element is stored in different place. Making the list take more space and require more time to get accessed. . While in Numpy, the arrays are stored in continuous funciton. So, one array will need only one pointer value to get accessed to all elements in that array. . import numpy as np array_obj = np.arange(12, dtype=np.uint8).reshape((3, 4)) def print_info(a): print(&#39;number of elements:&#39;, a.size) print(&#39;number of dimensions:&#39;, a.ndim) print(&#39;shape:&#39;, a.shape) print(&#39;data type:&#39;, a.dtype) print(&#39;strides:&#39;, a.strides) print(&#39;flags:&#39;) print(a.flags) print_info(array_obj) . . number of elements: 12 number of dimensions: 2 shape: (3, 4) data type: uint8 strides: (4, 1) flags: C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . In about example, each element is of dtype: uint8, so it take 1 bytes. To reach the first element in next row, it would have to skip 4 bytes. so the stride is (4, 1). . &quot;C_CONTIGUOUS&quot; and &quot;F_CONTIGUOUS&quot; states whether the variable is taking value from memory from column contiguous or fortran contiguous. For more explaination, I suggest this answer on stack-overflow. . print(&quot;Transpose array : Strides Changed.&quot;) # Taking Transpose print(array_obj.T) print_info(array_obj.T) print(array_obj.T.ravel(order=&quot;F&quot;)) print_info(array_obj.T.ravel(order=&quot;F&quot;)) print(array_obj.T.ravel(order=&quot;C&quot;)) print_info(array_obj.T.ravel(order=&quot;C&quot;)) . . Transpose array : Strides Changed. [[ 0 4 8] [ 1 5 9] [ 2 6 10] [ 3 7 11]] number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 4) flags: C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 1 2 3 4 5 6 7 8 9 10 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 4 8 1 5 9 2 6 10 3 7 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . Transposing the array change the behaviour of C_CONTIGUOUS and F_CONTIGUOUS. . Broadcasting . a = np.arange(12, dtype=np.uint8).reshape((4, 3)) b = np.arange(3, dtype=np.uint8) c= np.arange(4, dtype=np.uint8) print(a.shape, b.shape, c.shape) print(a + b) print(a + c) . . (4, 3) (3,) (4,) [[ 0 2 4] [ 3 5 7] [ 6 8 10] [ 9 11 13]] . ValueError Traceback (most recent call last) &lt;ipython-input-9-059306ffba40&gt; in &lt;module&gt; 7 8 print(a + b) -&gt; 9 print(a + c) ValueError: operands could not be broadcast together with shapes (4,3) (4,) . Boradcasting in numpy works when the less dimension is right align with more dimension array. . So, (4, 3) with (3, ) will work, but not with (4, ). (3, ) -&gt; ([4], 3) (4, ) -&gt; ([4], 4) . np.broadcast_arrays, broadcast the array to the desired shape. Notice the strides of dc, is (1, 0), because the row axis&#39; element is broadcasted. . da, dc = np.broadcast_arrays(a, c[:, np.newaxis]) print_info(dc) . . number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 0) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True (with WARN_ON_WRITE=True) ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . While nb.broadcast_arrys() take one array as reference and broadcast the other array to the same shape as reference one, we can also manipulate the arr to any shape we want withnp.lib.stride_tricks.as_strided(). . def repeat(arr, size): return np.lib.stride_tricks.as_strided( arr, shape=(size, ) + (arr.shape), strides = (0, ) + (arr.strides)) print(repeat(b, 5)) print_info(repeat(b, 5)) . . [[0 1 2] [0 1 2] [0 1 2] [0 1 2] [0 1 2]] number of elements: 15 number of dimensions: 2 shape: (5, 3) data type: uint8 strides: (0, 1) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . This function is often used to find the sliding window of the given array. . def sliding_window(arr, win_size): sliding_win = np.lib.stride_tricks.as_strided( arr, shape = (arr.shape[0]-win_size+1, win_size), strides = (arr.strides[0], arr.strides[0])) return sliding_win a = np.arange(10, dtype=np.uint8) print(sliding_window(a, 3)) print(np.mean(sliding_window(a, 3), axis=1)) . . [[0 1 2] [1 2 3] [2 3 4] [3 4 5] [4 5 6] [5 6 7] [6 7 8] [7 8 9]] [1. 2. 3. 4. 5. 6. 7. 8.] . Let&#39;s do something more exciting. We will find the mean of the sliding window. Resulting in the smoother graph. And we will then find mock moving average. . import matplotlib.pyplot as plt import numpy as np import altair as alt import pandas as pd indexs = np.arange(100) random_arrays = np.random.normal(0, 0.5, size=100) # Add some curve to the graph : Sexy, hehe random_arrays[30:60] += 1 # Let&#39;s smooth it out mean_2 = np.mean(sliding_window(random_arrays, 2), axis=1) padded_mean_2 = np.pad(mean_2, (1, 0)) mean_5 = np.mean(sliding_window(random_arrays, 5), axis=1) padded_mean_5 = np.pad(mean_5, (1, 3)) simple_ema = np.array([0.1, 0.15, 0.2, 0.25, 0.3]) ema_size = simple_ema.size ema = sliding_window(np.pad(random_arrays, (ema_size, ema_size-1), &#39;reflect&#39;), ema_size) * simple_ema ema = np.sum(ema, axis=1)[:-5] df = pd.DataFrame({ &#39;index&#39;:np.hstack((indexs, indexs, indexs, indexs)), &#39;values&#39;:np.hstack([random_arrays, padded_mean_2, padded_mean_5, ema]), &#39;label&#39;:[j for j in [&#39;random_arrays&#39;, &#39;mean with 2 neighbour&#39;, &#39;mean with 5 neighbour&#39;, &#39;mock Exponential Moving Average&#39;] for _ in range(100)] }) # Create a selection that chooses the nearest point &amp; selects based on x-value nearest = alt.selection(type=&#39;single&#39;, nearest=True, on=&#39;mouseover&#39;, fields=[&#39;index&#39;], empty=&#39;none&#39;) # The basic line line = alt.Chart(df).mark_line(interpolate=&#39;basis&#39;).encode( x=&#39;index:Q&#39;, y=&#39;values:Q&#39;, color=&#39;label:N&#39; ) # Transparent selectors across the chart. This is what tells us # the x-value of the cursor selectors = alt.Chart(df).mark_point().encode( x=&#39;index:Q&#39;, opacity=alt.value(0), ).add_selection( nearest ) # Draw points on the line, and highlight based on selection points = line.mark_point().encode( opacity=alt.condition(nearest, alt.value(1), alt.value(0)) ) # Draw text labels near the points, and highlight based on selection text = line.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=alt.condition(nearest, &#39;values:Q&#39;, alt.value(&#39; &#39;)) ) # Draw a rule at the location of the selection rules = alt.Chart(df).mark_rule(color=&#39;gray&#39;).encode( x=&#39;index:Q&#39;, ).transform_filter( nearest ) # Put the five layers into a chart and bind the data alt.layer( line, selectors, points, rules, text ).properties( width=600, height=300 ) # plt.plot(random_arrays, label=&#39;origin&#39;) # plt.plot(mean_2, label=&#39;mean with 2 neighbour&#39;) # plt.plot(mean_5, label=&#39;mean with 5 neighbour&#39;) # plt.plot(ema, label=&#39;mock Exponential Moving Average&#39;) # plt.legend() # plt.show() . . Well, as expected, exponentially moving average have some phase shift. It can be corrected with phase shift as described in adam paper. I am too lazy to implement it. hehe .",
            "url": "https://aungpaing98.github.io/blogs/numpy/notes/2020/01/12/Advanced-Numpy-PyData-Japan-19.html",
            "relUrl": "/numpy/notes/2020/01/12/Advanced-Numpy-PyData-Japan-19.html",
            "date": " • Jan 12, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Study Web from Scratch Notes",
            "content": "Why I started to learn Front-end . It seems like the end of study the machine learning is representing the model, and to the customer, to yourself. I am not saying I am already an expert in Machine Learning, not at all yet. But visualization of deep learning model intrigue me, how is the intermediate(hidden) layer of the model is behaving? Then I have a idea of putting my visualization model online. For that, I will have to know front-end. So my jorney to become front-end start. . How I start my Jornel . The very first thing is advice. I looked for all kinds of advices. Then plan for the whole course, what to study, and what I will focus on. Then, I decided to put main learning time on this website, as this have complete blog posts about every details I need to know as begineer. . So, Let&#39;s get start . Day1 . 2020-1-12-Tuesday . URL . URL stand for Uniform Resoure Locator, Each and every website on the cloud have its own URL, it is like an id. When we make a REQUEST throught the web, it is searching for that URL in the cloud and return us the website from that URL. But, actually, it is not URL that is the actual id of the website, IP is. . IP . IP stands for Internet Protocal, It is the id of the website. . For example, This block . URL IP . https://aungpaing98.github.io/blogs/ | 185.199.108.153 | . HTML . HTML stands for Hyper-Text Markup Language. HTML, with CSS are not programming language, they have no logics, conditions, loops and so on. They focus on the properties, style and layout(position) of the specific text in whole page. . As mentioned in the video, I will need to learn much more about HTML. . Document Sectioning | Document Meta-Data | Block Text Semantics | Inline Text Semantics | Image &amp; Multimedia | Embedded Contents | Scripting | Data Tables | . CSS . CSS stands for Cascading Style Sheet. We can use CSS to basically style each and every elements from HTML. Because there are repeatly used of same tag in a HTML file, using CSS can help to style all the tag which have similar semantic or properties with just one line. . JavaScript . JavaScript was first invented in 1995. Aside from the history, javascript is the real programming that provide the user interactivity and data storage for the webpage. . There are two main javascript that I was introduced. . Server Side (Backend?) | Browser Side (Frontend?) | . Seems like the server side and brower side have huge difference. For now, I guess for the browser side, the browser will have the function of Request for the data, Parsing the documents from the request, Layout and Painting the content. Furthermore, the browser will have to secure the user information from attack. And doing all this with minimum energy and delayed. . For the server side, the server will have to Provide the documents upon request, Store user information if passed. And Backup the information, making sure no data is loss due to breakdown on electricity. . Well, that is all my guess for now. I will get to that later. . SVG . SVG stands for Scalable Vector Grphic. What we saw images in typical format are .jpg or .png format. These are in bitmaps format. where the image is composed of bits, where SVG is composed of equations describing the line in that graphic(image). . The main advantage of SVG over jpg and png is that, it is scalable to any size and will not lose information, cause it is just the equation on the backbone. . For that, I will have to study grapic Software, like Sketch or Adobe Illustrator, which I have no idea about yet. . Day2 . 2020-1-13-Wednesday . Basic CSS . Like HTML, CSS is just a markup language. It is mainly used to style the HTML elements. . Selector . Selector in the CSS indicate the tag that we want to style on. Since there are many types of tags in HTML, there are also many types of Selector in CSS. . Selector css html element . Element Selector/ Tag Selector/ Type Selector | p {} | &lt;p&gt;&lt;/p&gt; | . ID Selector | #my-id {} | &lt;p id=&#39;my-id&#39;&gt;&lt;/p&gt; | . Class Selector | my-class {} | &lt;p class=&#39;myclass&#39;&gt;&lt;/p&gt; | . Attribute Selector | img[src] {} | &lt;img src=&quot;.jpg&quot;&gt; | . Pseudo-Class Selector | a.hover | work when mouse hover the link. | . Difference Types of Elements . Block Element . eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values. . Inline Element . eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block. . Basic Java Script . Java Script is the programming language. So, first let&#39;s start with definding a variable. . Variables . let a = &quot;Hello&quot; var b = &quot;World&quot; . Conditionals . if (condition) { DO THIS }else{ DO THIS } . Function . function name(*args, **kwargs) { } . Default Built-in Methods . alert : warning up when opening the webpage. | prompt : prompt window when opening the webpage. | getAttribute(&#39;color&#39;) : get color attribute of tag | setAttribute(&#39;color&#39;) : set color attribute of tag | document.querySelector(&#39;h1&#39;) : select h1 element | localStorage.setItem() : use localStoage API to store data | localStorage.getItem() : get data from localStoage API. | . Day3 . 2020-1-14-Thursday . What is in the head? . Head of the HTML part play the whole page information, including Title, description, charset, name, author, contents, linking to css and javascript. . Important: A nice website come from a nice head section. For example, the title and description in the web can affect the search result. The charset and lang in html affect the accessability of the website, for those who have difficultly in hearing. . eg. OpenGraphData from Facebook : . &lt;meta properties=&#39;og.image&#39; content=&quot;my profile.png&quot;&gt; . which will share the profile image as the thumbnail through social media for the post. . // defer here mean run HTML first, then run javascript &lt;script src=&quot;&quot; defer&gt;&lt;/script&gt; . // Increase Accessability &lt;html lang=&#39;en-US&#39;&gt; . HTML Text Fundamentals . tags in HTML use &lt;&gt; which give the text structure and meaning, it is also called Semantics. Using the right semantic can very mush improve your webpage quaility, both in search and accessability. . When writing texts in a web, or blog post, first, to be aware is making the hierarchy right. Title (&lt;h1&gt;) then subtilte (h2) and so on. . Also, with use of emphasize in html, it is better to be careful. . &lt;strong&gt; Use to Really Emphasize words. | &lt;em&gt; use to emphasize words. | &lt;b&gt; Make words bold. Not recommanded. | &lt;i&gt; Make words Italic. Not recommanded. | . Advanced Text Formatting . Advanced text formatting including learning more tag semantics. . description list : &lt;dl&gt; | description term : &lt;dl&gt; | description defination : &lt;dd&gt; | block quotes : &lt;blockquote cite=&quot;&quot;&gt; &lt;/blockquote&gt; | inline quotes : &lt;q&gt; &lt;/q&gt; | citation : &lt;cite&gt; &lt;/cite&gt; | Abbreviations : &lt;abbr&gt; | address : &lt;address&gt; &lt;/address&gt; | super and sub script : &lt;sup&gt; &lt;sub&gt; | computer code : &lt;code&gt; &lt;/code&gt; | indentation : &lt;pre&gt; &lt;/pre&gt; (container for code block where indendation is important : python.) | variable name : &lt;var&gt; | keyboard : &lt;kbd&gt; | output : &lt;samp&gt; | timestamp : &lt;time datetime=&quot;2021-1-11&quot;&gt; | . Creating Hyperlink . Simple linking: . &lt;a href = &quot;my.com&quot;&gt;Link to website&lt;/a&gt; &lt;a href = &quot;index.html&quot;&gt;Link to HTML File&lt;/a&gt; &lt;a href = &quot;#id&quot;&gt;Link to ID element&lt;/a&gt; &lt;a href = &quot;mailto:aungpaingcha1@gmail.com&quot;&gt;Mail to Aung Paing&lt;/a&gt; . Day4 . 2020-1-15-Friday . Document and Website Structure . Basic Structures of the webpage include: . header &lt;header&gt; | navigation bar &lt;nav&gt; | main content &lt;main&gt; | sidebar &lt;aside&gt; | footer &lt;footer&gt; | . . Planning a compelet websites . Steps you must go throught for minimum effort for maximum efficiency. . Common Specifications / Nav bar / Footer, etc. | Draw Sketch / Decide contents will be in the page. | brainstorm all other pages. | Card Sorting / Sort all contents into groups. | Sketch the whole rough site map. | Into Coding. | Debugging in HTML . The first thing we should know before going on, is that HTML is not a programming language. And in the browser side, it is not compile, but interpreted. And HTML is permissive code, meaning it will run even if there are some error. The language itself is designed to be that way, because back in the day, if it is not, most developer might find it difficult to work with. And HTML will not be here today. . Like most language, the error in HTML mainly consists of: . Syntax Error | Logic Error | . We can validate our .html file in https://validator.w3.org website. . Technical Terms . HTML (Hyper-Text Markup Language) CSS (Cascading Style Sheet) SVG (Scalable Vector Graphic) URL (Uniform Resource Locator) DOM (Document Object Model) Block Element : eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values, &lt;div&gt; is also and block element. Inline Element : eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block, &lt;span&gt; is also and inline element. .",
            "url": "https://aungpaing98.github.io/blogs/front-end/notes/html/css/javascript/2020/01/10/Web-Study-Notes.html",
            "relUrl": "/front-end/notes/html/css/javascript/2020/01/10/Web-Study-Notes.html",
            "date": " • Jan 10, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "CS231N Study Note",
            "content": "Abstrast . This course conducted by Standford focus on Computer Vision and Deep Learning, and is focus from the basic to the somehow advanced topic. This notebook contain the archives of the note of me taking from the course. If you would like to contribute to the notebook, please leave a comment in the below of the notebook. Link to youtube lecture . Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition . Brief introduction to the history of Computer Vision, Deep Learning and the problems to tackle in Computer Vision. Link to my Note . Lecture 2 | Image Classification Pipelines . Introduction to the image classification pipelines and train a simple model for image classification. Link to my Note . Lecture 3 | Loss Function and Optimization . Introduction to hinge loss, softmax function and optimization. Link to my Note . Lecture 4 | Backpropagation and Neural Network . Introduction to Neural Network backpropagation flow, equations and intuiation. Link to my Note . Lecture 5 | Convolutional Neural Network . History and modern about CNN and its basic operations. Link to my Note . Lecture 6 | Training Neural Network 1 . Basic Training Procedure hyperparameters optimization. Link to my Note . Lecture 7 | Training Neural Network 2 . Basic Training Procedure hyperparameters optimization. Link to my Note .",
            "url": "https://aungpaing98.github.io/blogs/cs231n/computer-vision/deep-learning/notes/2020/01/10/Standford-CS231N-Notes.html",
            "relUrl": "/cs231n/computer-vision/deep-learning/notes/2020/01/10/Standford-CS231N-Notes.html",
            "date": " • Jan 10, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "&lt;h1&gt;Welcome to Paing&#39;s Blog&lt;/h1&gt; &lt;/div&gt; &lt;div class=&#39;text-wrapper&#39;&gt; &lt;h2&gt;Interests&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Computer Vision&lt;/li&gt; &lt;li&gt;Machine Learning&lt;/li&gt; &lt;li&gt;Deep Learning&lt;/li&gt; &lt;li&gt;Data Science&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Recent Activities&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Junior Machine Learning Engineer at Omdena Global Challenge&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Skill&lt;/h2&gt; &lt;img src=&quot;https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/python/python.png&quot; width=&quot;40px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/markdown/markdown.png&quot; width=&quot;35px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://keras.io/img/logo.png&quot; width=&quot;100px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/pytorch-logo-dark.png&quot; width=&quot;100px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://github.com/fastai/fastai/blob/master/docs_src/images/company_logo.png?raw=true&quot; width=&quot;35px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;h2&gt;Publishcations&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9294048/&quot;&gt;Coverage Path Planning for Decomposition Reconfigurable Grid-Maps Using Deep Reinforcement Learning Based Travelling Salesman Problem,&quot; in IEEE Access, vol. 8, pp. 225945-225956, 2020, doi: 10.1109/ACCESS.2020.3045027&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Experiences&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Machine learning Internship at &lt;a href=&quot;https://www.acromyanmar.com&quot;&gt;Acroquest Myanmar Technology&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Member as Deep Learning engineer in project : &lt;a href=&quot;https://fb.watch/2Q7ELU4hwG/&quot;&gt;AI Face Recognition and Automatic Non-contact Temperature Measurement Device&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Teaching Assistant at Computer Vision and Machine Learning course &lt;a href=&quot;https://ytu-cvlab.github.io/mce-51069/&quot;&gt;mce-51069&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Speaker in YTU IoT Talk Shwe Ohh with Topic &quot;Blogging with FastPage&quot;&lt;/li&gt; &lt;li&gt;Junior Machine Learning Engineer at Omdena Global Challenge&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; .",
          "url": "https://aungpaing98.github.io/blogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://aungpaing98.github.io/blogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}