{
  
    
        "post0": {
            "title": "Study Web from Scratch Notes",
            "content": "Why I started to learn Front-end . It seems like the end of study the machine learning is representing the model, and to the customer, to yourself. I am not saying I am already an expert in Machine Learning, not at all yet. But visualization of deep learning model intrigue me, how is the intermediate(hidden) layer of the model is behaving? Then I have a idea of putting my visualization model online. For that, I will have to know front-end. So my jorney to become front-end start. . How I start my Jornel . The very first thing is advice. I looked for all kinds of advices. Then plan for the whole course, what to study, and what I will focus on. Then, I decided to put main learning time on this website, as this have complete blog posts about every details I need to know as begineer. . So, Let&#39;s get start . Day1 . 2020-1-12-Tuesday . URL . URL stand for Uniform Resoure Locator, Each and every website on the cloud have its own URL, it is like an id. When we make a REQUEST throught the web, it is searching for that URL in the cloud and return us the website from that URL. But, actually, it is not URL that is the actual id of the website, IP is. . IP . IP stands for Internet Protocal, It is the id of the website. . For example, This block . URL IP . https://aungpaing98.github.io/blogs/ | 185.199.108.153 | . HTML . HTML stands for Hyper-Text Markup Language. HTML, with CSS are not programming language, they have no logics, conditions, loops and so on. They focus on the properties, style and layout(position) of the specific text in whole page. . As mentioned in the video, I will need to learn much more about HTML. . Document Sectioning | Document Meta-Data | Block Text Semantics | Inline Text Semantics | Image &amp; Multimedia | Embedded Contents | Scripting | Data Tables | . CSS . CSS stands for Cascading Style Sheet. We can use CSS to basically style each and every elements from HTML. Because there are repeatly used of same tag in a HTML file, using CSS can help to style all the tag which have similar semantic or properties with just one line. . JavaScript . JavaScript was first invented in 1995. Aside from the history, javascript is the real programming that provide the user interactivity and data storage for the webpage. . There are two main javascript that I was introduced. . Server Side (Backend?) | Browser Side (Frontend?) | . Seems like the server side and brower side have huge difference. For now, I guess for the browser side, the browser will have the function of Request for the data, Parsing the documents from the request, Layout and Painting the content. Furthermore, the browser will have to secure the user information from attack. And doing all this with minimum energy and delayed. . For the server side, the server will have to Provide the documents upon request, Store user information if passed. And Backup the information, making sure no data is loss due to breakdown on electricity. . Well, that is all my guess for now. I will get to that later. . SVG . SVG stands for Scalable Vector Grphic. What we saw images in typical format are .jpg or .png format. These are in bitmaps format. where the image is composed of bits, where SVG is composed of equations describing the line in that graphic(image). . The main advantage of SVG over jpg and png is that, it is scalable to any size and will not lose information, cause it is just the equation on the backbone. . For that, I will have to study grapic Software, like Sketch or Adobe Illustrator, which I have no idea about yet. . Day2 . 2020-1-13-Wednesday . Basic CSS . Like HTML, CSS is just a markup language. It is mainly used to style the HTML elements. . Selector . Selector in the CSS indicate the tag that we want to style on. Since there are many types of tags in HTML, there are also many types of Selector in CSS. . Selector css html element . Element Selector/ Tag Selector/ Type Selector | p {} | &lt;p&gt;&lt;/p&gt; | . ID Selector | #my-id {} | &lt;p id=&#39;my-id&#39;&gt;&lt;/p&gt; | . Class Selector | my-class {} | &lt;p class=&#39;myclass&#39;&gt;&lt;/p&gt; | . Attribute Selector | img[src] {} | &lt;img src=&quot;.jpg&quot;&gt; | . Pseudo-Class Selector | a.hover | work when mouse hover the link. | . Difference Types of Elements . Block Element . eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values. . Inline Element . eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block. . Basic Java Script . Java Script is the programming language. So, first let&#39;s start with definding a variable. . Variables . let a = &quot;Hello&quot; var b = &quot;World&quot; . Conditionals . if (condition) { DO THIS }else{ DO THIS } . Function . function name(*args, **kwargs) { } . Default Built-in Methods . alert : warning up when opening the webpage. | prompt : prompt window when opening the webpage. | getAttribute(&#39;color&#39;) : get color attribute of tag | setAttribute(&#39;color&#39;) : set color attribute of tag | document.querySelector(&#39;h1&#39;) : select h1 element | localStorage.setItem() : use localStoage API to store data | localStorage.getItem() : get data from localStoage API. | . Day3 . 2020-1-14-Thursday . What is in the head? . Head of the HTML part play the whole page information, including Title, description, charset, name, author, contents, linking to css and javascript. . Important: A nice website come from a nice head section. For example, the title and description in the web can affect the search result. The charset and lang in html affect the accessability of the website, for those who have difficultly in hearing. . eg. OpenGraphData from Facebook : . &lt;meta properties=&#39;og.image&#39; content=&quot;my profile.png&quot;&gt; . which will share the profile image as the thumbnail through social media for the post. . // defer here mean run HTML first, then run javascript &lt;script src=&quot;&quot; defer&gt;&lt;/script&gt; . // Increase Accessability &lt;html lang=&#39;en-US&#39;&gt; . HTML Text Fundamentals . tags in HTML use &lt;&gt; which give the text structure and meaning, it is also called Semantics. Using the right semantic can very mush improve your webpage quaility, both in search and accessability. . When writing texts in a web, or blog post, first, to be aware is making the hierarchy right. Title (&lt;h1&gt;) then subtilte (h2) and so on. . Also, with use of emphasize in html, it is better to be careful. . &lt;strong&gt; Use to Really Emphasize words. | &lt;em&gt; use to emphasize words. | &lt;b&gt; Make words bold. Not recommanded. | &lt;i&gt; Make words Italic. Not recommanded. | . Advanced Text Formatting . Advanced text formatting including learning more tag semantics. . description list : &lt;dl&gt; | description term : &lt;dl&gt; | description defination : &lt;dd&gt; | block quotes : &lt;blockquote cite=&quot;&quot;&gt; &lt;/blockquote&gt; | inline quotes : &lt;q&gt; &lt;/q&gt; | citation : &lt;cite&gt; &lt;/cite&gt; | Abbreviations : &lt;abbr&gt; | address : &lt;address&gt; &lt;/address&gt; | super and sub script : &lt;sup&gt; &lt;sub&gt; | computer code : &lt;code&gt; &lt;/code&gt; | indentation : &lt;pre&gt; &lt;/pre&gt; (container for code block where indendation is important : python.) | variable name : &lt;var&gt; | keyboard : &lt;kbd&gt; | output : &lt;samp&gt; | timestamp : &lt;time datetime=&quot;2021-1-11&quot;&gt; | . Creating Hyperlink . Simple linking: . &lt;a href = &quot;my.com&quot;&gt;Link to website&lt;/a&gt; &lt;a href = &quot;index.html&quot;&gt;Link to HTML File&lt;/a&gt; &lt;a href = &quot;#id&quot;&gt;Link to ID element&lt;/a&gt; &lt;a href = &quot;mailto:aungpaingcha1@gmail.com&quot;&gt;Mail to Aung Paing&lt;/a&gt; . Day4 . 2020-1-15-Friday . Document and Website Structure . Basic Structures of the webpage include: . header &lt;header&gt; | navigation bar &lt;nav&gt; | main content &lt;main&gt; | sidebar &lt;aside&gt; | footer &lt;footer&gt; | . . Planning a compelet websites . Steps you must go throught for minimum effort for maximum efficiency. . Common Specifications / Nav bar / Footer, etc. | Draw Sketch / Decide contents will be in the page. | brainstorm all other pages. | Card Sorting / Sort all contents into groups. | Sketch the whole rough site map. | Into Coding. | Debugging in HTML . The first thing we should know before going on, is that HTML is not a programming language. And in the browser side, it is not compile, but interpreted. And HTML is permissive code, meaning it will run even if there are some error. The language itself is designed to be that way, because back in the day, if it is not, most developer might find it difficult to work with. And HTML will not be here today. . Like most language, the error in HTML mainly consists of: . Syntax Error | Logic Error | . We can validate our .html file in https://validator.w3.org website. . Technical Terms . HTML (Hyper-Text Markup Language) CSS (Cascading Style Sheet) SVG (Scalable Vector Graphic) URL (Uniform Resource Locator) DOM (Document Object Model) Block Element : eg. &lt;body&gt; is a block element which take up space and have mergin and spacing values, &lt;div&gt; is also and block element. Inline Element : eg. &lt;img&gt; is an inline element, not able to apply margin and spacing. To change it to have block properties, we can use display:block, &lt;span&gt; is also and inline element. .",
            "url": "https://aungpaing98.github.io/blogs/front-end/notes/html/css/javascript/2021/07/07/Web-Study-Notes.html",
            "relUrl": "/front-end/notes/html/css/javascript/2021/07/07/Web-Study-Notes.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "CS231N Study Note",
            "content": "Abstrast . This course conducted by Standford focus on Computer Vision and Deep Learning, and is focus from the basic to the somehow advanced topic. This notebook contain the archives of the note of me taking from the course. If you would like to contribute to the notebook, please leave a comment in the below of the notebook. Link to youtube lecture . Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition . Brief introduction to the history of Computer Vision, Deep Learning and the problems to tackle in Computer Vision. Link to my Note . Lecture 2 | Image Classification Pipelines . Introduction to the image classification pipelines and train a simple model for image classification. Link to my Note . Lecture 3 | Loss Function and Optimization . Introduction to hinge loss, softmax function and optimization. Link to my Note . Lecture 4 | Backpropagation and Neural Network . Introduction to Neural Network backpropagation flow, equations and intuiation. Link to my Note . Lecture 5 | Convolutional Neural Network . History and modern about CNN and its basic operations. Link to my Note . Lecture 6 | Training Neural Network 1 . Basic Training Procedure hyperparameters optimization. Link to my Note . Lecture 7 | Training Neural Network 2 . Basic Training Procedure hyperparameters optimization. Link to my Note .",
            "url": "https://aungpaing98.github.io/blogs/cs231n/computer-vision/deep-learning/notes/2021/07/07/Standford-CS231N-Notes.html",
            "relUrl": "/cs231n/computer-vision/deep-learning/notes/2021/07/07/Standford-CS231N-Notes.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "CS50 Study Note",
            "content": "Notes . This notebook is referenced from the CS50 course conducted by MIT lectures online from youtube. The course can be found in this youtube link. . Previews . My programming jorney starts from 3 years ago, when I first learn Python from youtube. It is a easy programming compare to others. Before that, I have attended lectures from university for basic comptuer science in C++ language. It was not a very productive one. And after I learnt Python, it is superficial, I now know that, to get the best performance of the algorithms, I need to know the logic behind all the pre-built function. That is why I started learning this course. . CS50, this lecture is really one of the top in my favorate list from my learning jorney. The lectures is energetic, explaning the lowest detail of the programming. I wish I have seen this lecture sooner. . Lectures 1 - C . The lecture is mainly conducted with using C langauge in first 5 lectures of the course. C language is the low level language meaning we can get the best performance in speed compare to other languages if the algorithms is optimized. . Good coding practice . To get the most efficient code, meaning it is functionable, able to get the desired output, it have a good design, most efficient and it have a good style, so everyone can understand the code. . $$ Code begin{cases} quad text{Functionable} quad text{Design} quad text{Style} end{cases} $$Command Line Interface (CLI) and Graphic User Interface (GUI) . Developer often use command line (terminal in mac) to execute the program. CLI is less user friendly than GUI, it needs a bit more knowledge but it is hackable and origin. The terminal is a platform which we can use complier to compile the code to machine code and open that machine code to get the output of the program. . So, the typical process is, . Write the code with text editor (visual studio code, atom, etc) | Compile the code in terminal with compiler and output machine code. | Run the machine code and output the result in terminal. | . Compiler is the program that is pre-written to convert the code that we write to machine code, that the computer understand. Different language have different compiler. And in mac, we need to install X-Code to run C program cause X-code is the compiler that contain multiple languages including C. .",
            "url": "https://aungpaing98.github.io/blogs/computer_science/basic/algorithms/2021/07/07/CS50.html",
            "relUrl": "/computer_science/basic/algorithms/2021/07/07/CS50.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Notes from Advanced Numpy (Scipy Japan 2019)",
            "content": "Abstrast . &quot;Scipy Japan 2019&quot;is the 18th annual Scientific Computing with Python conference. This note is taken from the &quot;Advanced Numpy&quot; topic, speech by Juan Nunez-Iglesias. The source code for speech is available at github. . I came across this on youtube. The speech give some aspect of Numpy that I am getting confused before, so, this notebook helps me to get more hand on Numpy. Let&#39;s get started. . A Little Introduction to DNA and RNA . The author is originally from the biologist background, so he introduced some ideas about DNA and RNA. Althought it is not much relevent to the subject, it is nice to know new things. . . Difference between List and Numpy Array . When we defind a variable in list, the true value of each element in the list is the pointer, which point to the location in hardware about where the value is stored. And each element is stored in different place. Making the list take more space and require more time to get accessed. . While in Numpy, the arrays are stored in continuous funciton. So, one array will need only one pointer value to get accessed to all elements in that array. . import numpy as np array_obj = np.arange(12, dtype=np.uint8).reshape((3, 4)) def print_info(a): print(&#39;number of elements:&#39;, a.size) print(&#39;number of dimensions:&#39;, a.ndim) print(&#39;shape:&#39;, a.shape) print(&#39;data type:&#39;, a.dtype) print(&#39;strides:&#39;, a.strides) print(&#39;flags:&#39;) print(a.flags) print_info(array_obj) . . number of elements: 12 number of dimensions: 2 shape: (3, 4) data type: uint8 strides: (4, 1) flags: C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . In about example, each element is of dtype: uint8, so it take 1 bytes. To reach the first element in next row, it would have to skip 4 bytes. so the stride is (4, 1). . &quot;C_CONTIGUOUS&quot; and &quot;F_CONTIGUOUS&quot; states whether the variable is taking value from memory from column contiguous or fortran contiguous. For more explaination, I suggest this answer on stack-overflow. . print(&quot;Transpose array : Strides Changed.&quot;) # Taking Transpose print(array_obj.T) print_info(array_obj.T) print(array_obj.T.ravel(order=&quot;F&quot;)) print_info(array_obj.T.ravel(order=&quot;F&quot;)) print(array_obj.T.ravel(order=&quot;C&quot;)) print_info(array_obj.T.ravel(order=&quot;C&quot;)) . . Transpose array : Strides Changed. [[ 0 4 8] [ 1 5 9] [ 2 6 10] [ 3 7 11]] number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 4) flags: C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 1 2 3 4 5 6 7 8 9 10 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False [ 0 4 8 1 5 9 2 6 10 3 7 11] number of elements: 12 number of dimensions: 1 shape: (12,) data type: uint8 strides: (1,) flags: C_CONTIGUOUS : True F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . Transposing the array change the behaviour of C_CONTIGUOUS and F_CONTIGUOUS. . Broadcasting . a = np.arange(12, dtype=np.uint8).reshape((4, 3)) b = np.arange(3, dtype=np.uint8) c= np.arange(4, dtype=np.uint8) print(a.shape, b.shape, c.shape) print(a + b) print(a + c) . . (4, 3) (3,) (4,) [[ 0 2 4] [ 3 5 7] [ 6 8 10] [ 9 11 13]] . ValueError Traceback (most recent call last) &lt;ipython-input-9-059306ffba40&gt; in &lt;module&gt; 7 8 print(a + b) -&gt; 9 print(a + c) ValueError: operands could not be broadcast together with shapes (4,3) (4,) . Boradcasting in numpy works when the less dimension is right align with more dimension array. . So, (4, 3) with (3, ) will work, but not with (4, ). (3, ) -&gt; ([4], 3) (4, ) -&gt; ([4], 4) . np.broadcast_arrays, broadcast the array to the desired shape. Notice the strides of dc, is (1, 0), because the row axis&#39; element is broadcasted. . da, dc = np.broadcast_arrays(a, c[:, np.newaxis]) print_info(dc) . . number of elements: 12 number of dimensions: 2 shape: (4, 3) data type: uint8 strides: (1, 0) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True (with WARN_ON_WRITE=True) ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . While nb.broadcast_arrys() take one array as reference and broadcast the other array to the same shape as reference one, we can also manipulate the arr to any shape we want withnp.lib.stride_tricks.as_strided(). . def repeat(arr, size): return np.lib.stride_tricks.as_strided( arr, shape=(size, ) + (arr.shape), strides = (0, ) + (arr.strides)) print(repeat(b, 5)) print_info(repeat(b, 5)) . . [[0 1 2] [0 1 2] [0 1 2] [0 1 2] [0 1 2]] number of elements: 15 number of dimensions: 2 shape: (5, 3) data type: uint8 strides: (0, 1) flags: C_CONTIGUOUS : False F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False . This function is often used to find the sliding window of the given array. . def sliding_window(arr, win_size): sliding_win = np.lib.stride_tricks.as_strided( arr, shape = (arr.shape[0]-win_size+1, win_size), strides = (arr.strides[0], arr.strides[0])) return sliding_win a = np.arange(10, dtype=np.uint8) print(sliding_window(a, 3)) print(np.mean(sliding_window(a, 3), axis=1)) . . [[0 1 2] [1 2 3] [2 3 4] [3 4 5] [4 5 6] [5 6 7] [6 7 8] [7 8 9]] [1. 2. 3. 4. 5. 6. 7. 8.] . Let&#39;s do something more exciting. We will find the mean of the sliding window. Resulting in the smoother graph. And we will then find mock moving average. . import matplotlib.pyplot as plt import numpy as np import altair as alt import pandas as pd indexs = np.arange(100) random_arrays = np.random.normal(0, 0.5, size=100) # Add some curve to the graph : Sexy, hehe random_arrays[30:60] += 1 # Let&#39;s smooth it out mean_2 = np.mean(sliding_window(random_arrays, 2), axis=1) padded_mean_2 = np.pad(mean_2, (1, 0)) mean_5 = np.mean(sliding_window(random_arrays, 5), axis=1) padded_mean_5 = np.pad(mean_5, (1, 3)) simple_ema = np.array([0.1, 0.15, 0.2, 0.25, 0.3]) ema_size = simple_ema.size ema = sliding_window(np.pad(random_arrays, (ema_size, ema_size-1), &#39;reflect&#39;), ema_size) * simple_ema ema = np.sum(ema, axis=1)[:-5] df = pd.DataFrame({ &#39;index&#39;:np.hstack((indexs, indexs, indexs, indexs)), &#39;values&#39;:np.hstack([random_arrays, padded_mean_2, padded_mean_5, ema]), &#39;label&#39;:[j for j in [&#39;random_arrays&#39;, &#39;mean with 2 neighbour&#39;, &#39;mean with 5 neighbour&#39;, &#39;mock Exponential Moving Average&#39;] for _ in range(100)] }) # Create a selection that chooses the nearest point &amp; selects based on x-value nearest = alt.selection(type=&#39;single&#39;, nearest=True, on=&#39;mouseover&#39;, fields=[&#39;index&#39;], empty=&#39;none&#39;) # The basic line line = alt.Chart(df).mark_line(interpolate=&#39;basis&#39;).encode( x=&#39;index:Q&#39;, y=&#39;values:Q&#39;, color=&#39;label:N&#39; ) # Transparent selectors across the chart. This is what tells us # the x-value of the cursor selectors = alt.Chart(df).mark_point().encode( x=&#39;index:Q&#39;, opacity=alt.value(0), ).add_selection( nearest ) # Draw points on the line, and highlight based on selection points = line.mark_point().encode( opacity=alt.condition(nearest, alt.value(1), alt.value(0)) ) # Draw text labels near the points, and highlight based on selection text = line.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=alt.condition(nearest, &#39;values:Q&#39;, alt.value(&#39; &#39;)) ) # Draw a rule at the location of the selection rules = alt.Chart(df).mark_rule(color=&#39;gray&#39;).encode( x=&#39;index:Q&#39;, ).transform_filter( nearest ) # Put the five layers into a chart and bind the data alt.layer( line, selectors, points, rules, text ).properties( width=600, height=300 ) # plt.plot(random_arrays, label=&#39;origin&#39;) # plt.plot(mean_2, label=&#39;mean with 2 neighbour&#39;) # plt.plot(mean_5, label=&#39;mean with 5 neighbour&#39;) # plt.plot(ema, label=&#39;mock Exponential Moving Average&#39;) # plt.legend() # plt.show() . . Well, as expected, exponentially moving average have some phase shift. It can be corrected with phase shift as described in adam paper. I am too lazy to implement it. hehe .",
            "url": "https://aungpaing98.github.io/blogs/numpy/notes/2021/07/07/Advanced-Numpy-PyData-Japan-19.html",
            "relUrl": "/numpy/notes/2021/07/07/Advanced-Numpy-PyData-Japan-19.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Basic Image Processing with Python",
            "content": "Image Acquisition . Images, taken from real life with camera, and then stored as the digital format in computer. In digital format, the images are represented by three color channel. (Red, Green and Blue). . In Python, we can read in the image with matplotlib library in following way : . img = matplotlib.image.imread(img_name) . After reading the image with above method, the variable img will contain the image value as the array in ndarray data type. We can also inspect the dimension(channel) of image in code with: . h, w, d = img.shape . 16, 16, 3 . As the above fig show, the mario image have 16 by 16 pixel values. So, h and w will be 16 x 16 and color image have 3 dimension. . Arithemetic Operations . Since Images are actually numbers, we could use functions to operate on the images. The most basic function would be adding, subtracting, multiplication and division. We will introduce Adding and Subtracting here in this blog post. . import matplotlib.image as mpimg import matplotlib.pyplot as plt import numpy as np import cv2 . # Helper Function for showing Images def imShow(imgs, titles=None): num = len(imgs) x = (num//4)+1 y = int(np.ceil(num/x)) plt.figure(figsize=(18,15)) for i in range(num): plt.subplot(x, y, i+1) cmap=None title=None if imgs[i].ndim==2:cmap=&#39;gray&#39; if titles!=None:title=titles[i] plt.imshow(imgs[i], cmap=cmap) plt.title(title,fontdict={&#39;fontsize&#39;:23}) plt.tight_layout() plt.show() . . Subtract Two Images . In the below Image, the subtracted result shows the difference between two images. . Note: While subtracting, we need to be careful of the data type range. Image arrays are typically in the range of 0 ~ 255. The data type is np.uint8. If it is negative value, it will subtract that negative value with 256. . Below show the example: . &#39;&#39;&#39;Because &#39;b&#39; is in the range of 0 ~ 255, while it exceed that value, it will subtract from 256. eg. here, &#39;b&#39; should be -5, so, it would be &#39;256-5 = 251&#39; &#39;&#39;&#39; a = np.array([5]) b = (a-10).astype(np.uint8) print(b) . . [251] . img1 = mpimg.imread(&#39;1.jpg&#39;) img2 = mpimg.imread(&#39;2.jpg&#39;) # First let&#39;s check their dimension assert img1.shape == img2.shape # Extend range so there won&#39;t be gibberish # diff = img2 - img1 diff = img2.astype(np.int16) - img1.astype(np.int16) diff[diff&lt;0] = 0 imShow([img1, img2, diff], [&#39;img1&#39;, &#39;img2&#39;, &#39;Difference&#39;]) . . Add Two Images . We can also add two images if they are in the same Dimension. . img1 = mpimg.imread(&#39;bird.jpg&#39;) img2 = mpimg.imread(&#39;back.jpg&#39;) h, w, d = img2.shape print(f&#39;Before resize : &#39;, img1.shape, img2.shape) img1 = cv2.resize(img1, (w, h)) print(f&#39;After resize : &#39;, img1.shape, img2.shape) add = img2.astype(np.int16) + img1.astype(np.int16) add[add&gt;255] = 255 imShow([img1, img2, add]) . . Before resize : (478, 717, 3) (421, 748, 3) After resize : (421, 748, 3) (421, 748, 3) . . Important: Both Adding and Subtracting two images need to have both same dimension for both inputs. . Geometric Transformations . Rotation, Crop . Rotation in the image is achieved by applying the transformation matrix to the image. | . M = cv2.getRotationMatrix2D((center_x, center_y), angle_to_rotate, scale) rotated = cv2.warpAffine(img, M, (x, y)) . Cropping is just simply Slicing of the image(numpy array). | . cropped = img[x_coor:x_coor, y_coor:y_coor] . # Rotation img = mpimg.imread(&#39;tower.jpg&#39;) h, w, d = img.shape simple = cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE) # More Flexible This Way M = cv2.getRotationMatrix2D((w/2, h/2), 90, 1) rotated = cv2.warpAffine(img, M, (h+100, w)) M = cv2.getRotationMatrix2D((w//2, h//2), 45, 0.5) rotated_ = cv2.warpAffine(img, M, (w, h)) imShow([img, simple, rotated, rotated_], [&#39;Tower&#39;, &#39;Simple Rotate&#39;, &#39;90 degree Rotated&#39;, &#39;45 degree Rotated&#39;]) . . # Crop [Image Slicing] img_copy = np.copy(img) door = img_copy[420:, 150:250, :] bicycle = img_copy[500:, 270:, :] imShow([img, door, bicycle], [&#39;Original Image&#39;, &#39;Door&#39;, &#39;Bicycle&#39;]) . . Color Image Transformation . RGB -&gt; BGR -&gt; HSV . Image can be converted to various color space by cv2.cvtColor(src, cv2.COLOR_). . Typically, if the image is read with matplotlib.image.imread(file_name), then it would read in with RGB format. And matplotlib.pyplot.imshow(img_array) would read the array as RGB format and display it. . While cv2.imread(file_name) would read in with BGR format and cv2.imshow() display as it take the array in BGR format. . Warning: read with matplotlib and plot with cv2 will result in Color space shift. . img = mpimg.imread(&#39;parrot.jpg&#39;) bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) imShow([img, bgr], [&#39;Original Image&#39;, &#39;BGR Image&#39;]) . . Unlike other color space, in HSV, the range for hue is from 0 ~ 179. . Hue value actually represent what we human understand of color. . eg. For red color, hue value would always be 0, regardless of the change in brightness and saturation. . img = mpimg.imread(&#39;parrot.jpg&#39;) hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) h = hsv[:, :, 0];s = hsv[:, :, 1];v = hsv[:, :, 2] print(&#39;hue t t&#39;, np.min(h), np.max(h), &#39; nsaturation t&#39;, np.min(s), np.max(s), &#39; nvalue t t&#39;, np.min(v), np.max(v)) imShow([h, s, v], [&#39;Hue&#39;, &#39;Saturation&#39;, &#39;Value&#39;]) . . hue 0 179 saturation 0 255 value 0 255 . Resizing Image . For the resizing, there are two cases: . Downsampling (Resized Image have lesser resolution than original One) | Upsampling (Resized Image have more resolution than original One) | . Also, there are many Interpolation methods to achieve resizing: . INTER_NEAREST (nearest-neighbour interpolation) | INTER_LINEAR (bilinear interpolation) | INTER_AREA (pixel area relation interpolation) [preferred for downsampling] | INTER_CUBIC (bicubic interpolation) | INTER_LANCZOS4 (lanczos interpolation) | . | . resized = cv2.resize(img, resized_dimension, interpolations=methods) . # Resizing img = mpimg.imread(&#39;lenna.png&#39;) h, w, d = img.shape dims = (w//2, h//2) dims_ = (w*2, h*2) downscale = cv2.resize(img, dims, interpolation=cv2.INTER_AREA) upscale = cv2.resize(img, dims_, interpolation=cv2.INTER_CUBIC) upscale_ = cv2.resize(img, dims_, interpolation=cv2.INTER_AREA) img = img[100:160, 100:160] downscale = downscale[50:80, 50:80] upscale = upscale[200:320, 200:320] upscale_ = upscale_[200:320, 200:320] imShow([img, downscale, upscale, upscale_], [f&#39;Original Image : {img.shape}&#39;, f&#39;Downscale Image : {downscale.shape}&#39;, f&#39;Upscale_cubic&#39;, f&#39;Upscale_area&#39;]) . . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Image Enhancing . Sometime, we get the image that is too dark or too bright, that it lose the information for the image. . For that, we could use transform in gray scale to hightlight the place in the image that we interest in. . The basic methods for that would be : . Negative | Log Transform | Gamma Transform | Contrast Stretching (Normalization) | Histogram Equalization | Here, we will focus on the first three method. . Note: Here, We show with just gray scale, But you can always try with all 3 Color spaces and stack them later with np.dstack((r, g, b)) if it is the color image. . Negative . Effect : Bright region turn to dark and dark region turn to bright.(invert of image). . Equation : $$y = 255-x$$ . Log Transform . Effect : Add brightness to where the image is dark. . Equation : $$y = log(c+x)$$ where : $c$ = constance, $x$ = Normalized pixel . Code : . # Normalized Image x = x/255 y = np.log(c + x) . Gamma Transform . Effect : Adjustable change in brightness with gamma value. . Equation : $$y = x**r$$ where : $r$ = gamma . Code : . # Normalized Image x = x/255 y = x**r . img_names = [&#39;bird.jpg&#39;, &#39;F3.jpg&#39;, &#39;PCL.jpg&#39;, &#39;cells.jpg&#39;, &#39;tree.jpg&#39;] for img_name in img_names: img = mpimg.imread(img_name) if img.ndim&gt;=3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) negative = 255-img img_copy = np.copy(img).astype(np.float32) img_copy /= 255 log = np.log(1.0+img_copy) # imShow([img, negative, log], [&#39;Orignal Image&#39;, &#39;Negative Image&#39;, &#39;Log Image&#39;]) imShow([img, negative, log], [&#39;Orignal Image&#39;, &#39;Negative&#39;, &#39;Log Image&#39;]) . . And Gamma correction with difference gamma value : . gamma0 = 0.5 gamma1 = 1 gamma2 = 1.5 img = mpimg.imread(&#39;tree.jpg&#39;) if img.ndim&gt;=3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) r0 = 1/gamma0 result0 = (img/255)**r0 r1 = 1/gamma1 result1 = (img/255)**r1 r2 = 1/gamma2 result2 = (img/255)**r2 imShow([img, result0, result1, result2], [&#39;original image&#39;, f&#39;gamma value : {gamma0}&#39;, f&#39;gamma value : {gamma1}&#39;, f&#39;gamma value : {gamma2}&#39;]) . . As Gamma value increase, the image get brighter. . Image Gradient . Edge Detection . Edge detection is the process of finding the boundaries (shape) of objects in the image. It works by detecting the change in pixel value in the image. . There are many ways to find the edge in the image. Mainly difference in the filter. Here, we will introduce two mostly used filter. . Sobel Filter (L1)sobel = cv2.Sobel(img, filter_size, dx, dy) . | Laplacian Filter (L2)laplace = cv2.Laplacian(img, cv2.CV_64F, ksize) . | After finding the edge, we could also use that to sharpen(enhance the edge) the image. So, we could Smooth (Blur) the image and sharp the image. . Smoothing (Blurring) Image . Commanly used method: . Gaussian Filterblurred = cv2.GaussianBlur(img, filter_size(tuple), std) . | Median Filter (Used to filter salt noise) . blurred = cv2.medianBlur(img, filter_size(int)) . Belowing show the Difference in Edge detection Method. . | def sobelEdge(img): sobelx = np.abs(cv2.Sobel(img, 3, 0, 1)).astype(np.uint32) sobely = np.abs(cv2.Sobel(img, 3,1, 0)).astype(np.uint32) sobel = np.sqrt(np.square(sobelx) + np.square(sobely)) sobel = (sobel/np.max(sobel)) * 255 return sobel.astype(np.uint8) def laplaceEdge(img): laplace = np.abs(cv2.Laplacian(img, cv2.CV_64F, ksize=3)) laplace = ((laplace/np.max(laplace)) * 255).astype(np.uint8) return laplace img_names = [&#39;dark.jpg&#39;, &#39;page.jpg&#39;,&#39;tower.jpg&#39;] for img_name in img_names: img = mpimg.imread(img_name) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) sobel = sobelEdge(gray) laplace = laplaceEdge(gray) imShow([gray, sobel, laplace], [f&#39;Original image{img.shape}&#39;, f&#39;Sobel{sobel.shape}&#39;, f&#39;Laplacian{laplace.shape}&#39;]) . . And the result of Smoothing and Sharpening of images. . def smooth(img): blurred = cv2.GaussianBlur(img, (9,9), 1) return blurred def sharp(img): blurred = cv2.GaussianBlur(img, (5, 5), 1).astype(np.float32) img = img.astype(np.float32) result = np.abs((1.5*img) - (0.5*blurred)) result = ((result/np.max(result)) * 255).astype(np.uint8) return result blurred = smooth(gray) sharped = sharp(gray) door = gray[420:, 150:250] door_blurred = blurred[420:, 150:250] door_sharped = sharped[420:, 150:250] imShow([gray, blurred, sharped, door, door_blurred, door_sharped], [&#39;Original Image&#39;, &#39;Smoothed Image&#39;, &#39;Sharped Image&#39;, &quot;Original Door&quot;, &#39;Blurred Door&#39;, &#39;Sharped Door&#39;]) . . Image Segmentation . The image show in plt.imshow() typically take three types of range. . uint8, range from (0~255)[total of 256 level] | float64, range from (0~1)[total of many floating level]&lt;eg. 0.1, 0.11, 0.111&gt; | Binary Image, contain only (0 and 1)[2 level]&lt;0 mean dark and 1 mean light&gt; | . Usually, we use binary image in Mask. . 1 mean object and 0 mean background. . # Gray Scale Image img1 = np.array([[0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255], [0, 50, 100, 150, 200, 255]]) # Binary Image img2 = np.array([[0, 1, 1, 1, 1, 1], [0, 0, 1, 1, 1, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1]]) imShow([img1, img2], [&#39;Gray scale Image&#39;, &#39;Binary Image&#39;]) . . For the thresholding, two methods can be used. . Global Thresholding (one threshold value for all region in the image) | Typically, we set the threshold value to random number, or we find the best threshold value by trial and error. Or we can use **otsu** method, which find the optimized threshold value from intensity histogram of image. . Adaptive Thresholding | Since the lighting condition in different region in a single image can be different, Adaptive thresholding method is often better than global method. . Adaptive threshold use difference threshold value in different region. . # Global Threshold img = mpimg.imread(&#39;page.jpg&#39;) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # 0 ~ 255 gray = cv2.medianBlur(gray, 5) glob_thresh = np.ones_like(gray) glob_thresh[gray&lt;25] = 0 # 0 &amp; 1 adap_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 3) _, otsu_thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) imShow([gray, glob_thresh, otsu_thresh, adap_thresh], [&#39;gray&#39;, &#39;global_threshold&#39;, &#39;otsu_Threshold&#39;, &#39;Adaptive_threshold&#39;]) . . Since thresholding process is transforming gray scale image to Binary one, it is also called binarization. . Different method for thresholding would be useful in different scenerios.The best way to find the best method is by trial and error. . For example, althought gobal thresholding method may not give better result than adaptive one, but its speed is faster casue there is not need to find the threshold value, by assigned by the user. . Morphological Transformations . Morphological transform is the transformation of shape in the binarization image. Typically used to modify the Mask (Binary Image). . Mostly Used methods are called: . Erosion (Reduce Shape) | Dilation (Expand Shape) | And the combination of these methods evolved to: . Opening (Disconnect closely related part) | Closing (Connect closely related Part) | img = mpimg.imread(&#39;cells.jpg&#39;) gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) gray = cv2.medianBlur(gray, 5) gray = gray[30:, :] # Let&#39;s do some thresholding thresh = np.zeros_like(gray) # threshold value here get by trial and error thresh[gray&gt;175] = 1 kernel = np.ones((5,5), np.uint8) #Erosion eroded = cv2.erode(thresh, kernel, iterations=1) #Dilation dilated = cv2.dilate(thresh, kernel, iterations=1) # Opening (Erosion + Dilation) opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel) # Closing (Dilation + Erosion) closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel) imShow([gray, thresh, eroded, dilated, opening, closing], [&#39;Gray Scale Image&#39;, &#39;Binary Threshold Image&#39;, &#39;Eroded Image&#39;, &#39;Dilated Image&#39;, &#39;Morpho Open&#39;, &#39;Morpho Close&#39;]) . . In Opening, the method open(separate) the closely connected part. Opening is achieved by first erosion, then dilation. . In Closing, the method close(connect) the closely connected part. Closing is achieved by first dilation, then erosion. . thresh_ = thresh[100:200, 150:250] open_ = opening[100:200, 150:250] close_ = closing[100:200, 150:250] imShow([thresh_, open_, close_], [&#39;Original Binary&#39;, &#39;Opeing&#39;, &#39;Closing&#39;]) . . Conclusion . The Above mentioned methods are all just basic image processing techniques. There are certainly many more state of the art algorithms. . But, If we get the idea that image are numbers and various functions could be apply to the image, then, we could modify and create intereting projects in computer vision. .",
            "url": "https://aungpaing98.github.io/blogs/image_processing/overview/2020/11/22/image_processing_overview.html",
            "relUrl": "/image_processing/overview/2020/11/22/image_processing_overview.html",
            "date": " • Nov 22, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://aungpaing98.github.io/blogs/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "&lt;h1&gt;Welcome to Paing&#39;s Blog&lt;/h1&gt; &lt;/div&gt; &lt;div class=&#39;text-wrapper&#39;&gt; &lt;h2&gt;Interests&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Computer Vision&lt;/li&gt; &lt;li&gt;Machine Learning&lt;/li&gt; &lt;li&gt;Deep Learning&lt;/li&gt; &lt;li&gt;Data Science&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Recent Activities&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Junior Machine Learning Engineer at Omdena Global Challenge&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Skill&lt;/h2&gt; &lt;img src=&quot;https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/python/python.png&quot; width=&quot;40px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/markdown/markdown.png&quot; width=&quot;35px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://keras.io/img/logo.png&quot; width=&quot;100px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/pytorch-logo-dark.png&quot; width=&quot;100px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;img src=&quot;https://github.com/fastai/fastai/blob/master/docs_src/images/company_logo.png?raw=true&quot; width=&quot;35px&quot; style=&quot;vertical-align:middle;margin:0px 20px&quot;&gt; &lt;h2&gt;Publishcations&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9294048/&quot;&gt;Coverage Path Planning for Decomposition Reconfigurable Grid-Maps Using Deep Reinforcement Learning Based Travelling Salesman Problem,&quot; in IEEE Access, vol. 8, pp. 225945-225956, 2020, doi: 10.1109/ACCESS.2020.3045027&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Experiences&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Machine learning Internship at &lt;a href=&quot;https://www.acromyanmar.com&quot;&gt;Acroquest Myanmar Technology&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Member as Deep Learning engineer in project : &lt;a href=&quot;https://fb.watch/2Q7ELU4hwG/&quot;&gt;AI Face Recognition and Automatic Non-contact Temperature Measurement Device&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Teaching Assistant at Computer Vision and Machine Learning course &lt;a href=&quot;https://ytu-cvlab.github.io/mce-51069/&quot;&gt;mce-51069&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Speaker in YTU IoT Talk Shwe Ohh with Topic &quot;Blogging with FastPage&quot;&lt;/li&gt; &lt;li&gt;Junior Machine Learning Engineer at Omdena Global Challenge&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; .",
          "url": "https://aungpaing98.github.io/blogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://aungpaing98.github.io/blogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}