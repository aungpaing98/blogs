<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Lecture 2 Image Classification Pipeline | Aung Paing’s Blogs</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Lecture 2 Image Classification Pipeline" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction to the image classification pipelines and train a simple model for image classification." />
<meta property="og:description" content="Introduction to the image classification pipelines and train a simple model for image classification." />
<link rel="canonical" href="https://aungpaing98.github.io/blogs/cs231n-lecture2/" />
<meta property="og:url" content="https://aungpaing98.github.io/blogs/cs231n-lecture2/" />
<meta property="og:site_name" content="Aung Paing’s Blogs" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-13T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://aungpaing98.github.io/blogs/cs231n-lecture2/","@type":"BlogPosting","headline":"Lecture 2 Image Classification Pipeline","dateModified":"2020-01-13T00:00:00-06:00","datePublished":"2020-01-13T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://aungpaing98.github.io/blogs/cs231n-lecture2/"},"description":"Introduction to the image classification pipelines and train a simple model for image classification.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blogs/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://aungpaing98.github.io/blogs/feed.xml" title="Aung Paing's Blogs" /><link rel="shortcut icon" type="image/x-icon" href="/blogs/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blogs/">Aung Paing&#39;s Blogs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blogs/about/">About</a><a class="page-link" href="/blogs/search/">Search</a><a class="page-link" href="/blogs/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Lecture 2 | Image Classification Pipeline</h1><p class="page-description">Introduction to the image classification pipelines and train a simple model for image classification.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-01-13T00:00:00-06:00" itemprop="datePublished">
        Jan 13, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blogs/categories/#computer-vision">computer-vision</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogs/categories/#deep-learning">deep-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogs/categories/#notes">notes</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogs/categories/#cs231n">cs231n</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#core-tasks-in-comptuer-vision">Core Tasks in Comptuer Vision</a></li>
<li class="toc-entry toc-h2"><a href="#challenges">Challenges</a></li>
<li class="toc-entry toc-h2"><a href="#attempts-have-been-made">Attempts have been made</a>
<ul>
<li class="toc-entry toc-h3"><a href="#data-driven-approach">Data-Driven Approach</a>
<ul>
<li class="toc-entry toc-h4"><a href="#1-use-nn-nearest-neighbour">1. Use NN (Nearest Neighbour)</a></li>
<li class="toc-entry toc-h4"><a href="#2-use-knn-k-nearest-neighbour">2. Use KNN (K-Nearest Neighbour)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#l1-loss-and-l2-loss">L1 Loss and L2 Loss</a></li>
<li class="toc-entry toc-h2"><a href="#setting-hyperparameters">Setting Hyperparameters</a></li>
<li class="toc-entry toc-h2"><a href="#linear-classification">Linear Classification</a>
<ul>
<li class="toc-entry toc-h3"><a href="#parametric-approach">Parametric Approach</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#interpreting-a-linear-classifier">Interpreting a Linear Classifier</a></li>
</ul><h2 id="core-tasks-in-comptuer-vision">
<a class="anchor" href="#core-tasks-in-comptuer-vision" aria-hidden="true"><span class="octicon octicon-link"></span></a>Core Tasks in Comptuer Vision</h2>

<ul>
  <li>Image Classification</li>
  <li>Semantic Segmentation</li>
  <li>Object Detection</li>
  <li>Instance Segmentation</li>
</ul>

<p>The problem in computer vision is that when reading in images to computer, what computer see is actually color bits representing RGB value. So, a slight change in the image can make huge different. That is called the semantic gap.</p>

<h2 id="challenges">
<a class="anchor" href="#challenges" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenges</h2>

<p>Below are the chanllenges that could change the value of the image even if the object in the image is the same.</p>
<ul>
  <li>ViewPoint variations (Camera View point change)</li>
  <li>Illumination (Lighting condition of image)</li>
  <li>Deformation (Shape of Object in the image changed)</li>
  <li>Occlusion (background object get blocked by object in front)</li>
  <li>Background Clutter (Color of object the same as background, eg. fox in snow)</li>
  <li>Intraclass variation (Various intra class in object. eg. bulldog and akita)</li>
</ul>

<h2 id="attempts-have-been-made">
<a class="anchor" href="#attempts-have-been-made" aria-hidden="true"><span class="octicon octicon-link"></span></a>Attempts have been made</h2>

<p>Input : Image
Process : Find edge, Convolute with template
Output :  Match -&gt; is cat, else –&gt; not cat.</p>

<h3 id="data-driven-approach">
<a class="anchor" href="#data-driven-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data-Driven Approach</h3>
<ul>
  <li>Collect Datasets.</li>
  <li>Use ML to train a classifier (Data Model).</li>
  <li>Evaluate with ML model.</li>
</ul>

<h4 id="1-use-nn-nearest-neighbour">
<a class="anchor" href="#1-use-nn-nearest-neighbour" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Use NN (Nearest Neighbour)</h4>
<p>Given a test image, compare it with all images from the train dataset, find the closest one, its label is the test label.<br>
Loss function : $L = \sum_p |I_1^P - I_2^P|$,<br>
Just subtract two images and sum the difference.</p>

<h4 id="2-use-knn-k-nearest-neighbour">
<a class="anchor" href="#2-use-knn-k-nearest-neighbour" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Use KNN (K-Nearest Neighbour)</h4>
<p>Instead of just the closed one, it select the k closed one. Majority of the k label is the test label. For example, Nearest Neightbour would be 1-NN, where the number of closest neighbour is set to 1.</p>

<h2 id="l1-loss-and-l2-loss">
<a class="anchor" href="#l1-loss-and-l2-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>L1 Loss and L2 Loss</h2>
<p><img src="https://github.com/aungpaing98/blogs/blob/master/_posts/resources/l1_l2_loss.png?raw=true" alt="L1 and L2 Loss Image">
As shown in the figure above, 3 elements with respect to the target will get difference loss value if different loss function was used.</p>

<p>In the course, he mentioned that if the input data is dimension aware, it should use L1 Loss. But commonly, most people choose L2 as their loss. Cause the relative distance between two points is the same in L2 Loss.<br>
<a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/">Intuiative Playground for KNN by Standford</a></p>

<h2 id="setting-hyperparameters">
<a class="anchor" href="#setting-hyperparameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting Hyperparameters</h2>

<p>In the above case, k-value is the hyperparameters, we won’t know which k-value will give out the best performance. So, we will divide the dataset to give us which hyperparameters should be used.</p>
<ul>
  <li>Train Dataset : The dataset to train our model.</li>
  <li>Validation Dataset : The dataset used for validation.</li>
  <li>Test Dataset : The dataset used for evaluation of model.<br>
</li>
</ul>

<p>If we split the dataset in such three fold, we can train the model, improve model by testing different hyper parameters on validation set, and test and give performance of the model on test dataset.<br>
Backthen, when there are no much datasets available, we use cross-validation method, which split data into folds, train and validation on each fold and average the result. It is not much used in deep learning nowaday. Just because there is no need.</p>

<blockquote>
  <p>Note: In real life, KNN on image will never be used. It is too slow on test time, memory inefficient and Loss algorithm is not good.</p>
</blockquote>

<h2 id="linear-classification">
<a class="anchor" href="#linear-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Linear Classification</h2>

<h3 id="parametric-approach">
<a class="anchor" href="#parametric-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Parametric Approach</h3>
<ul>
  <li>Collect Datasets.</li>
  <li>Use ML to train a classifier (Parametric Model).</li>
  <li>Evaluate with ML model.</li>
</ul>

<p><img src="https://github.com/aungpaing98/blogs/blob/master/_posts/resources/data_driven.png?raw=true" alt="">
<img src="https://github.com/aungpaing98/blogs/blob/master/_posts/resources/parametric.png?raw=true" alt=""></p>

<p>The difference between data-driven approach and parameteric approach is that the model in previous one try to memorize the dataset, while the later train the parameters $(W, b)$ in the model. This way, the model is robust to inputs and the model can be trained to get better performance with more dataset.</p>

<h2 id="interpreting-a-linear-classifier">
<a class="anchor" href="#interpreting-a-linear-classifier" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interpreting a Linear Classifier</h2>
<p>The course present an interesting way to interpret the model.</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="aungpaing98/blogs"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blogs/cs231n-lecture2/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blogs/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blogs/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blogs/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A Personal Blog Posts</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://www.facebook.com/aung.paing.jj.986" title="aung.paing.jj.986"><svg class="svg-icon grey"><use xlink:href="/blogs/assets/minima-social-icons.svg#facebook"></use></svg></a></li><li><a rel="me" href="https://github.com/aungpaing98" title="aungpaing98"><svg class="svg-icon grey"><use xlink:href="/blogs/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/aungpaing98" title="aungpaing98"><svg class="svg-icon grey"><use xlink:href="/blogs/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
